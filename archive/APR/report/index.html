<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Thomas William Boughen">
<meta name="dcterms.date" content="2024-05-31">

<title>Annual Progress Review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="doc_files/libs/clipboard/clipboard.min.js"></script>
<script src="doc_files/libs/quarto-html/quarto.js"></script>
<script src="doc_files/libs/quarto-html/popper.min.js"></script>
<script src="doc_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="doc_files/libs/quarto-html/anchor.min.js"></script>
<link href="doc_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="doc_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="doc_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="doc_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="doc_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-int" id="toc-sec-int" class="nav-link active" data-scroll-target="#sec-int"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-ext" id="toc-sec-ext" class="nav-link" data-scroll-target="#sec-ext"><span class="header-section-number">2</span> Extreme Value Theory</a>
  <ul class="collapse">
  <li><a href="#sec-ce" id="toc-sec-ce" class="nav-link" data-scroll-target="#sec-ce"><span class="header-section-number">2.1</span> Continuous Extremes</a></li>
  <li><a href="#sec-disc" id="toc-sec-disc" class="nav-link" data-scroll-target="#sec-disc"><span class="header-section-number">2.2</span> Discrete Extremes</a></li>
  <li><a href="#sec-mod" id="toc-sec-mod" class="nav-link" data-scroll-target="#sec-mod"><span class="header-section-number">2.3</span> Modelling</a></li>
  </ul></li>
  <li><a href="#sec-net" id="toc-sec-net" class="nav-link" data-scroll-target="#sec-net"><span class="header-section-number">3</span> Networks</a>
  <ul class="collapse">
  <li><a href="#mathematical-definitions" id="toc-mathematical-definitions" class="nav-link" data-scroll-target="#mathematical-definitions"><span class="header-section-number">3.1</span> Mathematical Definitions</a></li>
  <li><a href="#sec-gen" id="toc-sec-gen" class="nav-link" data-scroll-target="#sec-gen"><span class="header-section-number">3.2</span> Network Generative Models</a>
  <ul class="collapse">
  <li><a href="#general-preferential-attachment-gpa" id="toc-general-preferential-attachment-gpa" class="nav-link" data-scroll-target="#general-preferential-attachment-gpa">General Preferential Attachment (GPA)</a></li>
  <li><a href="#barabási-albert-ba" id="toc-barabási-albert-ba" class="nav-link" data-scroll-target="#barabási-albert-ba">Barabási-Albert (BA)</a></li>
  <li><a href="#uniform-attachment-ua" id="toc-uniform-attachment-ua" class="nav-link" data-scroll-target="#uniform-attachment-ua">Uniform Attachment (UA)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-meth" id="toc-sec-meth" class="nav-link" data-scroll-target="#sec-meth"><span class="header-section-number">4</span> Methods</a>
  <ul class="collapse">
  <li><a href="#sec-realmodel" id="toc-sec-realmodel" class="nav-link" data-scroll-target="#sec-realmodel"><span class="header-section-number">4.1</span> Modelling degree distributions</a></li>
  <li><a href="#fitting-model-to-the-data" id="toc-fitting-model-to-the-data" class="nav-link" data-scroll-target="#fitting-model-to-the-data"><span class="header-section-number">4.2</span> Fitting model to the data</a></li>
  <li><a href="#gpa-analyses" id="toc-gpa-analyses" class="nav-link" data-scroll-target="#gpa-analyses"><span class="header-section-number">4.3</span> GPA analyses</a>
  <ul class="collapse">
  <li><a href="#the-preferential-attachment-function" id="toc-the-preferential-attachment-function" class="nav-link" data-scroll-target="#the-preferential-attachment-function">The Preferential Attachment Function</a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  </ul></li>
  <li><a href="#a-conjecture" id="toc-a-conjecture" class="nav-link" data-scroll-target="#a-conjecture"><span class="header-section-number">4.4</span> A Conjecture</a></li>
  </ul></li>
  <li><a href="#discussion-and-next-steps" id="toc-discussion-and-next-steps" class="nav-link" data-scroll-target="#discussion-and-next-steps"><span class="header-section-number">5</span> Discussion and Next Steps</a></li>
  
  
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="doc.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="doc.odt"><i class="bi bi-file"></i>OpenOffice</a></li></ul></div></nav>
</div>
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Annual Progress Review</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Thomas William Boughen </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Newcastle University
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 31, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="sec-int" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Since the aim is to gain understanding about the behaviour of the degree distribution of networks at the right tail, it seems natural to look to using methods from extreme value theory.</p>
</section>
<section id="sec-ext" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Extreme Value Theory</h1>
<p>This section begins with a review of the theory and methodology for modelling the extreme values of continuous random variables, before moving to considerations for modelling the extreme values of discrete random variables.</p>
<section id="sec-ce" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-ce"><span class="header-section-number">2.1</span> Continuous Extremes</h2>
<p>Studying the properties of the extreme values of a random variable first requires determining what exactly is considered to be an extreme value. In this section extreme values of two kinds are considered, both of which can be characterised.</p>
<p>The first kind of extreme value considers the distribution of block maxima. That is, for a set of independent and identically distributed (iid) random variables <span class="math inline">\(X_1,\ldots,X_n\)</span> with common cumulative density function (cdf) <span class="math inline">\(F\)</span> what is the limiting distribution of <span class="math inline">\(M_n = \max\{X_1,\ldots,X_n\}\)</span>?</p>
<p>Clearly, as <span class="math inline">\(n\rightarrow \infty\)</span>, the block maxima <span class="math inline">\(M_n\)</span> converges almost surely to the right endpoint of <span class="math inline">\(F\)</span>. However, standardising the block maxima allows for some characterisation of the limiting distribution.</p>
<div id="thm-evt" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Fisher–Tippett–Gnedenko Theorem) </strong></span>With <span class="math inline">\(X_1, \ldots,X_n \overset{\mathrm{iid}}{\sim} F\)</span> and <span class="math inline">\(\{ a_n\}_{n\ge0}, \{ b_n\}_{n\ge0}\)</span> such that:</p>
<p><span class="math display">\[\lim_{n\rightarrow\infty}\Pr\left(\displaystyle\frac{1}{a_n}[M_n-b_n]\le x\right) = G(x),\]</span> for some non-degenerate <span class="math inline">\(G\)</span>.</p>
<p>Then <span class="math inline">\(F\)</span> is said to be in the (maximum) domain of attraction of <span class="math inline">\(G\)</span>, denoted <span class="math inline">\(F\in\mathcal D(G)\)</span> ,and <span class="math inline">\(G\)</span> is of one of three types:</p>
<ul>
<li>Gumbel: <span class="math inline">\(\Lambda(x) = \exp\{-\exp(-x)\},\quad x \in \mathbb R\)</span></li>
<li>Fréchet: <span class="math inline">\(\Phi_\alpha(x) = \exp\{-x^{-\alpha}\},\quad x\ge 0,\alpha&gt;0\)</span></li>
<li>Negative-Weibull: <span class="math inline">\(\Psi_\alpha(x) = \exp\{-x^{-a}\},\quad x&lt;0,\alpha&gt;0\)</span></li>
</ul>
</div>
<p>Each of these three types defines a domain of attraction.</p>
<div id="def-doa" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Domains of Attraction) </strong></span>The three domains of attraction that result from <a href="#thm-evt">Theorem&nbsp;1</a> have the following equivalent conditions:</p>
<p>For a distribution with cdf <span class="math inline">\(F\)</span> and survival function <span class="math inline">\(\bar F\)</span> that has right endpoint <span class="math inline">\(x_F\)</span> given by: <span class="math display">\[
x_F = \sup\{x \in \mathbb R \cup\{\infty\}:F(x)&lt;1\}
\]</span> the distribution belongs to each domain of attraction subject to the conditions below:</p>
<p><strong>If there exists a positive function a</strong></p>
<ul>
<li>Type I/Gumbel/<span class="math inline">\(\mathcal D(\Lambda)\)</span>:</li>
</ul>
<p><span class="math display">\[
\lim_{x\uparrow x_F} \displaystyle\frac{\bar F(x+ta(x))}{\bar F(x)} = e^{-t},\quad \forall t\in\mathbb R
\]</span></p>
<p><strong>If</strong> <span class="math inline">\(x_F=\infty\)</span>:</p>
<ul>
<li>Type II/Fréchet/<span class="math inline">\(\mathcal D (\Phi_\alpha)\)</span>:</li>
</ul>
<p><span class="math display">\[
\lim_{x\rightarrow\infty} \displaystyle\frac{\bar F(tx)}{\bar F(x)} = x^{-\alpha}, \quad \forall t&gt;0 \quad \text{ for some } \alpha&gt;0
\]</span></p>
<p><strong>If</strong> <span class="math inline">\(x_F&lt;\infty\)</span>:</p>
<ul>
<li>Type III/Negative-Weibull/<span class="math inline">\(\mathcal D(\Psi_\alpha)\)</span>:</li>
</ul>
<p><span class="math display">\[
\lim_{h\downarrow 0}\displaystyle\frac{\bar F(x_F-xh)}{\bar F(x_F-h)} = x^\alpha, \quad\alpha&gt;0
\]</span></p>
</div>
<p>The parameter <span class="math inline">\(\alpha\)</span> in <a href="#def-doa">Definition&nbsp;1</a> and <a href="#thm-evt">Theorem&nbsp;1</a> is called the extreme value index.</p>
<p>Here, distributions in the Gumbel domain are referred to as light tailed, distributions in the Negative-Weibull domain are referred to as short tailed, and those in the Fréchet are referred to as heavy tailed.This terminology for heavy tailed distributions in different ot some of the literature that defined a heavy tailed distribution as one that decays slower than exponential. However the terminology used here is also widely used.</p>
<p>Throughout this report functions will be referred to as regularly varying or slowly varying, what is meant by this is formally deined below:</p>
<div id="def-rv" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 (Regular Variation) </strong></span>A positive,real valued, measurable function <span class="math inline">\(f\)</span> is said to be regularly varying at infinity with index <span class="math inline">\(\gamma\)</span> if for all <span class="math inline">\(t&gt;0\)</span>:</p>
<p><span class="math display">\[
\lim_{x\rightarrow\infty}\displaystyle\frac{f(tx)}{f(x)} = x^{\gamma}.
\]</span> If <span class="math inline">\(\gamma =0\)</span>, then <span class="math inline">\(f\)</span> is instead said to be slowly varying at infinity.</p>
</div>
<p>Note that the condition for a distribution to belong to the Fréchet domain of attraction is equivalent to saying that the survival function <span class="math inline">\(\bar F\)</span> is regularly varying with index <span class="math inline">\(-\alpha\)</span>.</p>
<p>In addition to heavy tailed distributions it is also useful to define what will be referred to as super heavy tailed distributions. This term is often just refers to specific distributions such as the log-Cauchy ,log-Gamma,and log-Weibull distributions but <span class="citation" data-cites="fmh09">[<a href="#ref-fmh09" role="doc-biblioref">1</a>]</span> provides a more precise definition below:</p>
<div id="def-sup" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 (Super Heavy Tails) </strong></span>A distribution is with survival function <span class="math inline">\(\bar F\)</span> is said to have super heavy tails if: <span class="math display">\[
\lim_{x\rightarrow\infty}\displaystyle\frac{\bar F(tx)}{\bar F (x)} = 1,\qquad \forall t&gt;0
\]</span> That is, a distribution is called super heavy if its survival function is slowly varying.</p>
</div>
<p>The three main types of extremal distribution (Gumbel, Fréchet and Negative-Weibull) can be united into one distribution, called the Generalised Extreme Value (GEV) distribution.</p>
<div id="def-gev" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4 (Generalised Extreme Value Distribution) </strong></span>Denoted by <span class="math inline">\(\text{GEV}(\mu,\sigma,\xi)\)</span> the distribution is characterised by three parameters <span class="math inline">\(\mu \in \mathbb R\)</span> the location, <span class="math inline">\(\sigma\in \mathbb R^+\)</span> the scale, and the shape <span class="math inline">\(\xi\in \mathbb R\)</span>. It has support on <span class="math inline">\(\{x\in \mathbb R:1+\xi(x-\mu)/\sigma &gt; 0\}\)</span> and has cdf given by:</p>
<p><span class="math display">\[
G(x) = \begin{cases}\exp\left\{-\left(1+\displaystyle\frac{\xi(x-\mu)}{\sigma}\right)_+^{-1/\xi}\right\},&amp;\xi\ne0\\
\exp\left\{-\exp\left(-\displaystyle\frac{x-\mu}{\sigma}\right)\right\},&amp;\xi=0.
\end{cases}
\]</span></p>
</div>
<p>The three types of extremal distribution are obtained from changing the shape parameter <span class="math inline">\(\xi\)</span>, which corresponds to <span class="math inline">\(1/\alpha\)</span> in <a href="#thm-evt">Theorem&nbsp;1</a>. This change is generally made so that the largest <span class="math inline">\(\xi\)</span> corresponds to heavier tails of the distribution. Specifically, <span class="math inline">\(\xi&lt;0\)</span>, <span class="math inline">\(\xi=0\)</span>, <span class="math inline">\(\xi&gt;0\)</span>, correspond to the negative Weibull, Gumbel and the Fréchet domains of attraction respectively.</p>
<p>Another kind of extreme values are the observations above a large threshold, like the limiting distribution of block maxima, the limiting distribution of these extreme values can be characterised by the generalised pareto (GP) distribution.</p>
<div id="def-gp" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5 (Generalised Pareto Distribution) </strong></span>Consider a random variable <span class="math inline">\(X\)</span> with the same cdf <span class="math inline">\(F\)</span> as in <a href="#thm-evt">Theorem&nbsp;1</a>, the Generalised Pareto (GP) distribution can be obtained by using the GEV distribution and conditional probability such that for large enough threshold the GP distribution approximately describes the conditional distribution of threshold exceedances. More precisely, for sufficiently large threshold <span class="math inline">\(u\)</span> and the change of variable to <span class="math inline">\(Y=X-u\)</span>: <span class="math display">\[
\Pr(Y\le y | Y&gt;0) = H(y) = \begin{cases}
1-\left(1+\displaystyle\frac{\xi y}{\sigma}\right)^{-1/\xi},&amp;y&gt;0,\xi\ne 0 \\
1-\exp\left(-\displaystyle\frac{y}{\sigma}\right),&amp;y&gt;0,\xi = 0
\end{cases}
\]</span></p>
</div>
<p>Since this distribution was obtained using a <span class="math inline">\(\text{GEV}(\mu,\sigma^*,\xi)\)</span> the shape parameter <span class="math inline">\(\xi\)</span> is identical in both distributions and the shape parameter <span class="math inline">\(\sigma\)</span> is defined such that <span class="math inline">\(\sigma = \sigma^* + \xi(u-\mu)\)</span>.</p>
<p>It is also possible to derive the result without using the GEV, as shown in [REF].</p>
</section>
<section id="sec-disc" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-disc"><span class="header-section-number">2.2</span> Discrete Extremes</h2>
<p>A lot of <a href="#sec-ce">Section&nbsp;2.1</a> is appropriate only for continuous random variables and some of the results may not hold in a discrete setting. In particular, a continuous distribution <span class="math inline">\(F\)</span> being in certain domain of attraction may not necessarily imply that a discretisation of <span class="math inline">\(F\)</span> remains in that domain of attraction.</p>
<div id="def-disc" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6 (Discretisation) </strong></span>The discretisation of a distribution with cdf <span class="math inline">\(F\)</span> is given by</p>
<p><span class="math display">\[F^*(n) = F(n) - F(n-1), \quad n   \in \mathbb Z\]</span></p>
</div>
<p><span class="citation" data-cites="shimura12">[<a href="#ref-shimura12" role="doc-biblioref">2</a>]</span> provides conditions for a discretisation of a continuous distribution to belong to the same domain of attraction. In particular the following theorem which corresponds to Theorem 1 in <span class="citation" data-cites="shimura12">[<a href="#ref-shimura12" role="doc-biblioref">2</a>]</span>.</p>
<div id="thm-shimura1" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Domain of attraction consistency) </strong></span>&nbsp;</p>
<ol type="a">
<li>Every discretisation of distribution in <span class="math inline">\(\mathcal D(\Phi_\alpha)\)</span> remains in <span class="math inline">\(\mathcal D(\Phi_\alpha)\)</span>.</li>
<li>The discretisation of a distribution remains in <span class="math inline">\(\mathcal D(\Lambda)\)</span> if and only if the original is in <span class="math inline">\(\mathcal D(\Lambda)\cap \mathcal L\)</span>.</li>
</ol>
<p>Where <span class="math inline">\(\mathcal L\)</span> is the set of long-tailed distributions that have the property: <span class="math display">\[
\lim_{x\rightarrow \infty}\displaystyle\frac{\overline F(x+1)}{\overline F(x)} = 1   
\]</span></p>
</div>
<p>In addition <span class="citation" data-cites="shimura12">[<a href="#ref-shimura12" role="doc-biblioref">2</a>]</span> introduces a quantity useful for determining the domain of a attraction that a discrete distribution belongs to.</p>
<div id="def-omega" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7 (Omega Function) </strong></span>For a distribution <span class="math inline">\(F\)</span> with survival function <span class="math inline">\(\overline F\)</span> and some <span class="math inline">\(n\in\mathbb Z^+\)</span> let:</p>
<p><span class="math display">\[
\Omega(F,n) = \left(\log\displaystyle\frac{\overline F (n+1)}{\overline F (n+2)}\right)^{-1} - \left(\log\displaystyle\frac{\overline F (n)}{\overline F (n+1)}\right)^{-1}
\]</span></p>
</div>
<p>This quantity plays an important role in <a href="#sec-meth">Section&nbsp;4</a> when determining the domain of attraction to which the degree distribution of a network generative model belongs. In particular a discrete distribution is recoverable to the Fréchet domain of attraction <span class="math inline">\(\mathcal D(\Phi_\alpha)\)</span> if: <span class="math display">\[
\lim_{n\rightarrow\infty}\Omega(F,n) = \alpha^{-1}
\]</span></p>
<p>Applying ideas from <a href="#sec-ce">Section&nbsp;2.1</a> to modelling discrete random variables has been approached from many different directions. What follows is a overview of some of the approaches that have been taken but will see use in this report.</p>
<p><span class="citation" data-cites="hds24">[<a href="#ref-hds24" role="doc-biblioref">3</a>]</span> note that using the GP distribution as an approximation in a discrete setting leads to bias in the likelihood function and can lead to it being inadequate for modelling. They propose two other peaks over threshold methods that rely on parametric families of discrete distributions. The first, what they refer to as the discrete generalised Pareto approximation is based on an extension of the discrete survival function. The second, the generalised Zipf distribution is obtained from an extension of the probability mass function. Both methods are motivated theoretically for modelling of a large class of discrete distributions and are shown in the paper to either match or outperform using the GP to model discrete data directly.</p>
<p><span class="citation" data-cites="agn22">[<a href="#ref-agn22" role="doc-biblioref">4</a>]</span> first introduce an extended GP distribution, a continuous distribution that extends the idea of obtaining GP values from a probability integral transform (PIT) of <span class="math inline">\(U(0,1)\)</span> draws and instead considers a PIT of draws from any distribution on <span class="math inline">\((0,1)\)</span> such as a beta distribution. This distribution is then discretised into their discrete extended GP distribution.</p>
<p>The approach that will be used in <a href="#sec-meth">Section&nbsp;4</a> follows <span class="citation" data-cites="Rohrbeck_2018">[<a href="#ref-Rohrbeck_2018" role="doc-biblioref">5</a>]</span>, and first requires defining a discretisation of the GP distribution.</p>
<div id="def-igp" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8 (Intergral Generalised Pareto Distribution (IGP)) </strong></span>Consider a random variable <span class="math inline">\(X\)</span> with cdf <span class="math inline">\(F\)</span>, and consider the random variable <span class="math inline">\(Y=\lfloor X \rfloor\)</span>. From <a href="#def-gp">Definition&nbsp;5</a>, <span class="math inline">\(X|X&gt;u \sim GP(\sigma, \xi)\)</span> for some sufficiently large <span class="math inline">\(u\in \mathbb R^+\)</span> and it can be obtained that the distribution of <span class="math inline">\(Y|Y&gt;u\)</span> has distribution defined below:</p>
<p><span class="math display">\[
\Pr(Y=y&gt;Y&gt;u) = \left(1+\displaystyle\frac{\xi(y+1-\lceil u\rceil)}{\sigma_0+\xi\lceil u\rceil}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-\lceil u\rceil)}{\sigma_0+\xi\lceil u\rceil}\right)_+^{-1/\xi}
\]</span></p>
<p>For <span class="math inline">\(y=\lceil u\rceil,\lceil u\rceil+1, \ldots\)</span> and <span class="math inline">\(\xi \in \mathbb R\)</span> and <span class="math inline">\(u, \sigma_0 \in \mathbb R^+.\)</span></p>
</div>
</section>
<section id="sec-mod" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-mod"><span class="header-section-number">2.3</span> Modelling</h2>
<p>The results from <a href="#sec-ce">Section&nbsp;2.1</a> allow the GEV and GP to be fitted to the block maxima and exceedances respectively. An example of where modelling the GEV may be useful are when modelling monthly high temperatures, fitting the GEV to historic data of peak monthly temperatures may allow for future prediction of these temperatures. Fitting the GP may be useful in other scenarios such as modelling the strength of solar flares.</p>
<p>Typically, when fitting the GP, a sufficiently high threshold needs to be specified beforehand. <span class="citation" data-cites="coles2001">[<a href="#ref-coles2001" role="doc-biblioref">6</a>]</span> provides some empirical methods for specifying the threshold, one approach is to use a threshold stability plot that uses maximum likelihood to estimate the parameters of the GP for a large range of thresholds. The threshold can be chosen as the point across all of the plots after which the values of the parameters seems stable. One particular issue when fitting the GP to data, is that the likelihoods cannot be compared for different thresholds as changing the threshold changes the amount of data being used.</p>
<p>Another more recent approach shown by <span class="citation" data-cites="mac2012">[<a href="#ref-mac2012" role="doc-biblioref">7</a>]</span>, uses a spliced threshold mixture to model the threshold exceedances where one distribution is assumed for the bulk of the data and the GP is used for those values above the threshold. This approach can also be applied in the discrete setting, and is what is used in <a href="#sec-meth">Section&nbsp;4</a>. A general cases of the model is given below</p>
<div id="def-mixigp" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9 (IGP Spliced Mixture) </strong></span><span class="math display">\[
f(y) = \begin{cases}
(1-\phi)g(x), &amp; y=1,2,\ldots, v\\
\phi\left[\left(1+\displaystyle\frac{\xi(y+1-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}\right],&amp;y=v+1, v+2,\ldots
\end{cases}
\]</span> where <span class="math inline">\(g\)</span> is the pmf of some discrete distribution with support equal to <span class="math inline">\(\{1,2,\ldots,v\}\)</span>.</p>
</div>
</section>
</section>
<section id="sec-net" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Networks</h1>
<p>Networks are the data sources that the results from <a href="#sec-ext">Section&nbsp;2</a> will be used to analyse. Networks appear across a wide range of fields when attempting to represent complex systems and the relationships between the components within them.</p>
<p>This section will being with an introduction to the basics of networks and working with them in mathematics and probability, including the concept of degree distribution. Then, a look at a few network generation models and limiting results for the degree distributions of the networks they generate.</p>
<section id="mathematical-definitions" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="mathematical-definitions"><span class="header-section-number">3.1</span> Mathematical Definitions</h2>
<p>Throughout this section, graphs constructed from vertices and edges will be used as an analogue for these networks, so it is appropriate to begin with some mathematical definitions for exactly what that means.</p>
<div id="def-net" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 10 (Graph) </strong></span>A graph <span class="math inline">\(G = (V,E)\)</span> is constructed from a vertex set <span class="math inline">\(V\)</span> and an edge set <span class="math inline">\(E\)</span>. The edge set can take on one of two forms depending on if the graph is directed or un-directed. If the graph is directed then <span class="math inline">\(E\subseteq V^2\)</span> i.e the edge set is contained within the set of ordered pairs of vertices, whereas if the graph is <strong>un-directed</strong> then <span class="math inline">\(E\subseteq [V]^2\)</span>, where <span class="math display">\[
[V]^2 = \{\{u,v\}:u,v\in V\}
\]</span> i.e.&nbsp;the edge set is contained within the set of un-ordered pairs of vertices.</p>
</div>
<div id="def-deg" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 11 (Degree of un-directed graphs) </strong></span>For an un-directed graph a vertex’s degree denoted <span class="math inline">\(d(v)\)</span> for <span class="math inline">\(v\in V\)</span> is the number of edges that are connected to vertex <span class="math inline">\(v\)</span>: <span class="math display">\[
d(v) = |\{e\in E : v \in e\}|
\]</span></p>
</div>
<div id="def-dirdeg" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 12 (Degree of directed graphs) </strong></span>Directed graphs have something analogous, called the in-degree <span class="math inline">\(d_{in}\)</span>, out-degree <span class="math inline">\(d_{out}\)</span> and total degree <span class="math inline">\(d_{tot}\)</span>. The in-degree of a vertex <span class="math inline">\(v\)</span> is the number edges with endpoint at <span class="math inline">\(v\)</span>, whereas the out-degree is the number of edges with start point at <span class="math inline">\(v\)</span> and the total degree is the sum of these i.e.:</p>
<span class="math display">\[\begin{align*}
d_{in}(v)&amp;= |\{(w_1,w_2)\in E: w_2=v \}|\\
d_{out}(v) &amp;= |\{(w_1,w_2)\in E: w_1=v \}|\\
d_{tot}(v) &amp;= d_{in}(v) + d_{out}(v)
\end{align*}\]</span>
</div>
<p>There are many reasons to analyse network like data, one of which is to gain an insight into the mechanics that governed the growth of the network. The next sub-section is focused on presenting several network generative models, that may be able to describe how real networks grow. For now, the focus will be on the degree distributions of these network generative models.</p>
</section>
<section id="sec-gen" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-gen"><span class="header-section-number">3.2</span> Network Generative Models</h2>
<p>It is useful to be able to model the way a network may have grown using simple rules as the subsequent model can then be used to simulate how the network may grow in future and provide insights into the underlying mechanics of the system the network represents. These models are also sometimes called mechanistic models in the literature. Also, although they are referred to as network generative models, graphs are still being used in the rules that govern how the generative model works. The focus here is on preferential attachment models, but it should be noted that network generative models are not limited to this class of models. Some other well known models include the Erdős-Réyni model[REF] and the small-world model[REF].</p>
<p>This section begins by detailing a fairly simple generative model and its limiting results for the degree distribution, followed by two special cases of the first model and their results.</p>
<section id="general-preferential-attachment-gpa" class="level3">
<h3 class="anchored" data-anchor-id="general-preferential-attachment-gpa">General Preferential Attachment (GPA)</h3>
<p>Under this model, at each time step one vertex is added to the network and brings an edge with it that connects the existing vertices with a probability proportional to some function of the vertices degrees.</p>
<div id="def-gpa" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13 (General Preferential Attachment Model) </strong></span>Starting with a graph <span class="math inline">\(G_1 = (V_1, E_1) = (\{1,\ldots,m_0\}, \emptyset)\)</span>. At each following time step <span class="math inline">\(t&gt;1\)</span> the graph <span class="math inline">\(G_t = (V_t, E_t)\)</span> is generated by the following rules:</p>
<ol type="1">
<li><strong>Growth:</strong> Add a new vertex to the vertex set i.e.&nbsp;<span class="math display">\[
V_t = V_{t-1} \cup \{t\}
\]</span></li>
<li><strong>Preferential Attachment:</strong> Add <span class="math inline">\(m\le m_0\)</span> edges connecting the new vertex those already in the graph <span class="math inline">\(\{1,\ldots,t-1\}\)</span> selected at random with weights proportional to a function of their degree i.e.: <span class="math display">\[
E_t  = E_{t-1} \cup \{\tilde e_1,\ldots,\tilde e_m\}
\]</span> where <span class="math inline">\(\tilde e_j = \{t,\tilde v\}\)</span> and <span class="math inline">\(\tilde v = i\)</span> with weights <span class="math display">\[
\displaystyle\frac{g(d(i))}{\sum_{w\in V_{t-1}} g(d(i))}, \qquad i\in V_{t-1}
\]</span></li>
</ol>
<p>for some function <span class="math inline">\(g: \mathbb Z \mapsto \mathbb R^+\setminus\{0\}\)</span>, which will be referred to as the preferential attachment function</p>
</div>
<!-- [^1]: The probabilities are proportional to the degree minus one to align with the results from \[GPA REF\] -->
<p>There are some asymptotic results that have been derived for the case when <span class="math inline">\(m=1\)</span>, making the process generate a random tree.</p>
<section id="limiting-degree-distribution" class="level4">
<h4 class="anchored" data-anchor-id="limiting-degree-distribution">Limiting Degree Distribution</h4>
<p>In <span class="citation" data-cites="rudas07">[<a href="#ref-rudas07" role="doc-biblioref">8</a>]</span> the limiting degree distribution was calculated in terms of the preferential attachment function and does not have a general explicit form. It is defined as follows, let <span class="math inline">\(\lambda^*\)</span> be the solution, if it exists, to:</p>
<p><span class="math display">\[
1=\sum_{n=1}^\infty \prod_{i=1}^{n-1}\displaystyle\frac{g(i)}{g(i)+\lambda}
\]</span> then the limiting degree distribution of a network resulting from the GPA model has probability mass function (pmf):</p>
<p><span class="math display">\[
f(k) = \displaystyle\frac{\lambda^*}{g(k) + \lambda^*}\prod_{i=0}^{k-1}\displaystyle\frac{g(i)}{g(i)+\lambda^*}
\]</span></p>
</section>
</section>
<section id="barabási-albert-ba" class="level3">
<h3 class="anchored" data-anchor-id="barabási-albert-ba">Barabási-Albert (BA)</h3>
<p>The GPA model has several special cases, when <span class="math inline">\(g\)</span> is the identity function i.e <span class="math inline">\(g(k)=k\)</span>, it becomes the BA model <span class="citation" data-cites="Barabasi99">[<a href="#ref-Barabasi99" role="doc-biblioref">9</a>]</span>.</p>
<div id="def-ba" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 14 (Barabási-Albert Model) </strong></span>Starting with a graph <span class="math inline">\(G_1 = (V_1, E_1)\)</span> where <span class="math inline">\(V_1 = \{1,\ldots,m_0\}\)</span> and <span class="math inline">\(E_1 = \{\{v\}:v\in V_1\}\)</span> i.e a graph with <span class="math inline">\(m_0\)</span> vertices with one self-loop each. At each time step <span class="math inline">\(t&gt;1\)</span> the graph <span class="math inline">\(G_t = (V_1, E_1)\)</span> is generated by the following rules:</p>
<ol type="1">
<li><strong>Growth:</strong> Add a new vertex to the vertex set i.e.&nbsp;<span class="math display">\[
V_t = V_{t-1} \cup \{t\}
\]</span></li>
<li><strong>Preferential Attachment:</strong> Add <span class="math inline">\(m\le m_0\)</span> edges between the new vertex and those already in the graph with probability proportional to each vertices degree i.e.&nbsp;<span class="math display">\[
E_t  = E_{t-1} \cup \{\tilde e_1, \ldots, \tilde e_m\}
\]</span> where each new edge <span class="math inline">\(\tilde e_i = \{t, \tilde v_i\}\)</span>(<span class="math inline">\(i=1,\ldots, m\)</span>) has <span class="math inline">\(\tilde v_i\)</span> sampled independently without replacement from <span class="math inline">\(V_{t-1}\)</span> with probability: <span class="math display">\[
\frac{d(\tilde v_i)}{\sum_{u\in V_{t-1}}d(u)}
\]</span></li>
</ol>
</div>
<section id="limiting-degree-distriubtion" class="level4">
<h4 class="anchored" data-anchor-id="limiting-degree-distriubtion">Limiting Degree Distriubtion</h4>
<p>In <span class="citation" data-cites="barabasibook">[<a href="#ref-barabasibook" role="doc-biblioref">10</a>]</span> it was shown that for large values of <span class="math inline">\(t\)</span>, the limiting degree distribution of a network produces by this model is:</p>
<p><span class="math display">\[
f(k) = \frac{2m(m+1)}{k(k+1)(k+2)}, \qquad k\geq m
\]</span></p>
<p>[KARAMATA] states that since this pmf is regularly varying with exponent 2, then so is its cmf and it is in the Fréchet domain of attraction <span class="math inline">\(\mathcal D(\Phi_2)\)</span>.</p>
</section>
</section>
<section id="uniform-attachment-ua" class="level3">
<h3 class="anchored" data-anchor-id="uniform-attachment-ua">Uniform Attachment (UA)</h3>
<p>The final special case presented here is obtained from setting the preferential attachment function <span class="math inline">\(g\)</span> to be some constant value.</p>
<div id="def-ua" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 15 (Uniform Attachment Model) </strong></span>Start with a graph <span class="math inline">\(G_1 = (V_1, E_1) = (\{1,\ldots,m_0\}, \emptyset)\)</span>, at each time step <span class="math inline">\(t&gt;1\)</span> the graph is denoted by <span class="math inline">\(G_t=(V_t, E_t)\)</span> and generated by repeating the following two steps:</p>
<ol type="1">
<li><strong>Growth:</strong> Add a new vertex to the vertex set i.e.&nbsp;<span class="math display">\[
V_t=V_{t-1}\cup\{t\}
\]</span></li>
<li><strong>Uniform Attachment:</strong> Add <span class="math inline">\(m\le m_0\)</span> edges between the new vertex and those already in the graph with probability proportional to each vertices degree i.e.&nbsp;<span class="math display">\[
E_t  = E_{t-1} \cup \{\tilde e_1, \ldots, \tilde e_m\}
\]</span> where each new edge <span class="math inline">\(\tilde e_i = \{t, \tilde v_i\}\)</span>(<span class="math inline">\(i=1,\ldots, m\)</span>) has <span class="math inline">\(\tilde v_i\)</span> sampled independently without replacement from <span class="math inline">\(V_{t-1}\)</span> with probability: <span class="math display">\[
\frac{1}{\sum_{u\in V_{t-1}}1} = \frac{1}{|V_{t-1}|}
\]</span></li>
</ol>
</div>
<section id="limiting-degree-distribution-1" class="level4">
<h4 class="anchored" data-anchor-id="limiting-degree-distribution-1">Limiting Degree Distribution</h4>
<p>As showing in <span class="citation" data-cites="Barabasi99">[<a href="#ref-Barabasi99" role="doc-biblioref">9</a>]</span> the expected degree distribution of this model for large values of <span class="math inline">\(t\)</span> is approximately: <span class="math display">\[
f(k) = \displaystyle\frac{e}{m}\exp\left(-\displaystyle\frac{k}{m}\right),\qquad k \ge m
\]</span> Although this was not shown rigourously and treats the degree of a vertex as a continuous random variable, this is an shifted exponential distribution with left endpoint <span class="math inline">\(m\)</span> and rate parameter <span class="math inline">\(1/m\)</span> and as such is in the Gumbel domain of attraction.</p>
<p>If <span class="math inline">\(m=1\)</span>, it is possible to get a more precise result from the result regarding the limiting degree distribution of the GPA. By setting the preferential attachment function <span class="math inline">\(g(k) = \lambda^*\)</span>, the can be shown that the limiting degree distribution is: <span class="math display">\[
f(k) = \left(\frac{1}{2} \right)^{k}, \qquad k=1,2,\ldots
\]</span> This distribution also occupies the Gumbel domain of attraction.</p>
</section>
</section>
</section>
</section>
<section id="sec-meth" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Methods</h1>
<p>The aim of this section is to investigate the degree distribution of real networks and compare them to the results obtained for the generative models in <a href="#sec-gen">Section&nbsp;3.2</a>. First, a look at what the degree distributions of real networks look like.</p>
<div class="panel-fill panel-grid">
<div class="g-col-24">
<div class="cell panel-fill" data-fig-cap-location="top" data-fig.asp="1">
<div class="cell-output-display">
<div id="fig-survs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-survs-1.png" class="img-fluid figure-img" style="width:66.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Plots of survial functions of real networks degrees</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p><a href="#fig-survs">Figure&nbsp;1</a> shows the survival function of the degrees of various real networks as well as “BAsim” and “UAsim” which were generated using the corresponding schemes in <a href="#sec-gen">Section&nbsp;3.2</a>. Additionally, the theoretical limiting degree distribution of both the UA model and the BA model (for m=1) are included on the plots. Visually it seems that neither of these models are adequate for modelling the growth of the real networks shown here.</p>
<p>To further investigate this, <a href="#sec-realmodel">Section&nbsp;4.1</a> considers fitting a model to these data that will provide insight into what would be needed from a network generative model such that it flexible enough to capture the variation of shapes of degree distribution in real networks.</p>
<section id="sec-realmodel" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-realmodel"><span class="header-section-number">4.1</span> Modelling degree distributions</h2>
<p>As mentioned in <a href="#sec-mod">Section&nbsp;2.3</a>, the method used here to model the extreme values of the data will be a spliced threshold mixture. Specifically, it will be a spliced threshold mixture of a power law and a discretisation of the generalised pareto distribution similar to what is defined in <span class="citation" data-cites="Rohrbeck_2018">[<a href="#ref-Rohrbeck_2018" role="doc-biblioref">5</a>]</span>.</p>
<div id="def-pligp" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16 (Power-Law IGP Distribution) </strong></span><span class="math display">\[
f(y) = \begin{cases}
(1-\phi)\displaystyle\frac{y^{-(\alpha+1})}{\sum_{k=1}^v}k^{\alpha+1}, &amp; y=1,2,\ldots, v\\
\phi\left[\left(1+\displaystyle\frac{\xi(y+1-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}\right],&amp;y=v+1, v+2,\ldots
\end{cases}
\]</span></p>
</div>
</section>
<section id="fitting-model-to-the-data" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="fitting-model-to-the-data"><span class="header-section-number">4.2</span> Fitting model to the data</h2>
<p>The values of the parameters in the model for each data set were estimated under the Bayesian framework using a Metropolis within Gibbs sampler. Below are plots showing the same data as in <a href="#fig-survs">Figure&nbsp;1</a> but with the mean and 95% confidence intervals of the survival function of the model for each data-set.</p>
<div class="cell" data-fig-cap-location="top" data-fig.asp="1">
<div class="cell-output-display">
<div id="fig-fits1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-fits1-1.png" class="img-fluid figure-img" style="width:66.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Plots of truncated survial functions of real networks degrees</figcaption>
</figure>
</div>
</div>
</div>
<p>As show by <a href="#fig-fits1">Figure&nbsp;2</a> the model seems to fit the data quite well, below are some plot summarising each of the parameters for each of the models:</p>
<div class="cell" data-fig.asp="0.4">
<div class="cell-output-display">
<div id="fig-thresh" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-thresh-1.png" class="img-fluid figure-img" style="width:66.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Posterior of threshold (<span class="math inline">\(v\)</span>)</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell quarto-layout-cell" data-fig.asp="1" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-alpha" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-alpha-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Posterior of power law index (<span class="math inline">\(\alpha\)</span>)</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell quarto-layout-cell" data-fig.asp="1" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-scale" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-scale-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Posterior of scale (<span class="math inline">\(\sigma\)</span>)</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell quarto-layout-cell" data-fig.asp="1" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-shape" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-shape-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Posterior of shape (<span class="math inline">\(\xi\)</span>)</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell quarto-layout-cell" data-fig.asp="1" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell-output-display">
<div id="fig-alpha-inv" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-alpha-inv-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Posterior of inverse of power law index (<span class="math inline">\(1/\alpha\)</span>)</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p><a href="#fig-thresh">Figure&nbsp;3</a> shows that for ‘arenas-meta’ and ‘UAsim’ the posterior of the threshold is extremely concentrated, so much so that only one threshold is used. In the case of ‘arenas-meta’, this value is 1 meaning that the power law index <span class="math inline">\(\alpha\)</span> (<a href="#fig-alpha">Figure&nbsp;4</a>) is free to be any value that is permitted by the prior, which is anything on the positive real line, explaining the very diffuse posterior. The threshold for ‘UAsim’ is so low due to the magnitude of the values in the data and is much more concentrated because of the sample size.</p>
<p>The variety of values that <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\xi\)</span> take across all of the data sets shown in <a href="#fig-alpha">Figure&nbsp;4</a> and <a href="#fig-shape">Figure&nbsp;6</a>, makes it clear that none of these models could have been the result of either the BA model or the UA model when <span class="math inline">\(m=1\)</span>. Changing <span class="math inline">\(m\)</span> may indeed change the degree distribution, but it would also change the left endpoint of the degree distributions as each vertex would join the graph with <span class="math inline">\(m\)</span> edges leaving no vertices with degree less that <span class="math inline">\(m\)</span>.</p>
</section>
<section id="gpa-analyses" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="gpa-analyses"><span class="header-section-number">4.3</span> GPA analyses</h2>
<p>So far it has been shown that neither the BA model nor the UA model can adequately capture the range of type of degree distributions of real networks. So, a natural place to start when attempting to expand the range of possible degree distributions is the more general model, the GPA. This section, will use results from <span class="citation" data-cites="shimura12">[<a href="#ref-shimura12" role="doc-biblioref">2</a>]</span> and <a href="#sec-ext">Section&nbsp;2</a> to investigate the possible types of degree distribution that may arise from different preferential attachment functions in the GPA model.</p>
<section id="the-preferential-attachment-function" class="level3">
<h3 class="anchored" data-anchor-id="the-preferential-attachment-function">The Preferential Attachment Function</h3>
<p>From here on the preferential functions that will be used for the GPA model will be of the form: <span class="math display">\[
g(k) = k^\gamma, \qquad \gamma&gt;0.
\]</span></p>
<p>This allows for investigating the cases where the preferential attachment function is sub-linear and when it is super-linear.</p>
</section>
<section id="section" class="level3">
<h3 class="anchored" data-anchor-id="section"></h3>
<p>As discussed in <a href="#sec-disc">Section&nbsp;2.2</a>, the limiting value of <span class="math inline">\(\Omega(F,n)\)</span> can give a lot of information about the behaviour of a discrete distribution at extreme values. Below is a plot showing the value of this quantity as <span class="math inline">\(n\)</span> increases for various different values of <span class="math inline">\(\gamma\)</span>.</p>
<div class="cell" data-hash="doc_cache/html/fig-omega_8bd989601a24a20daf71ed638aeb772c">
<div class="cell-output-display">
<div id="fig-omega" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-omega-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Plot of <span class="math inline">\(\Omega(F,n)\)</span> for various <span class="math inline">\(\gamma \in (0.7,1.3)\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-omega">Figure&nbsp;8</a> shows that for <span class="math inline">\(\gamma&lt;1\)</span> <span class="math inline">\(\Omega(F,n)\)</span> seems to approach 0 as <span class="math inline">\(n\)</span> increases, whereas for <span class="math inline">\(\gamma=1\)</span> <span class="math inline">\(\Omega(F,n)\)</span> seems to converge to finite non-zero limit which is to be expected as this corresponds to the BA model which has limiting degree distribution in the Fréchet domain of attraction. However, for <span class="math inline">\(\gamma&gt;1\)</span> the value of <span class="math inline">\(\Omega(F,n)\)</span> appears to diverge and does not approach a finite limit.</p>
<p><span class="citation" data-cites="shimura12">[<a href="#ref-shimura12" role="doc-biblioref">2</a>]</span> does not provide any results in particular for the case of <span class="math inline">\(\Omega(F,n)\)</span> diverging but if the definition of slow variation and thus super-heavy tails is viewed as regular variation in the limit as <span class="math inline">\(\alpha\)</span> goes to infinity then the following can be obtained.</p>
<div id="cor-omg" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 1 </strong></span>For a distribution <span class="math inline">\(F\)</span> with survival function <span class="math inline">\(\overline F\)</span> and some <span class="math inline">\(n\in\mathbb Z^+\)</span>, if: <span class="math display">\[
\lim_{n\rightarrow\infty} \Omega(F,n) = \lim_{\alpha\downarrow0} \alpha^{-1} = \infty
\]</span> then <span class="math inline">\(F\)</span> has super heavy tails</p>
</div>
<p>This is further supported by <a href="#fig-shtail">Figure&nbsp;9</a> below, which shows the value of the quantity from <a href="#def-sup">Definition&nbsp;3</a> for increasing values of <span class="math inline">\(n\)</span> and values of <span class="math inline">\(\gamma\)</span> in the range <span class="math inline">\((1,2)\)</span>. The plot shows the quantity approaching <span class="math inline">\(1\)</span> for all values of <span class="math inline">\(\gamma\)</span> as <span class="math inline">\(n\)</span> increases, suggesting that the limiting degree distribution of the GPA model with <span class="math inline">\(g(k) = k^\gamma,\gamma&gt;1\)</span> has super heavy tails.</p>
</section>
</section>
<section id="a-conjecture" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="a-conjecture"><span class="header-section-number">4.4</span> A Conjecture</h2>
<p>The results from this subsection suggest that for super-linear preferential attachment functions the GPA model has limiting degree distribution with super heavy tails. This, along with results for the linear case in <a href="#sec-gen">Section&nbsp;3.2</a> and sub-linear cases in <span class="citation" data-cites="barabasibook">[<a href="#ref-barabasibook" role="doc-biblioref">10</a>]</span> lead to the following conjecture.</p>
<div id="cnj-gpa" class="theorem conjecture">
<p><span class="theorem-title"><strong>Conjecture 1 </strong></span>The GPA model is only capable of producing three different types of degree distribution:</p>
<ol type="1">
<li>Gumbel: sub-linear preferential attachment function</li>
<li>Fréchet <span class="math inline">\(\mathcal D(\Phi_2)\)</span>: linear preferential attachment function</li>
<li>Super heavy tails: super-linear preferential attachment function</li>
</ol>
</div>
<p>This means that under the framework presented here, even the GPA model is no where near close to being able to capture the range of types of degree distribution found in real networks.</p>
<div class="cell" data-hash="doc_cache/html/fig-shtail_ad04d2c92b748f58139c6e5f19057de3">
<div class="cell-output-display">
<div id="fig-shtail" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="doc_files/figure-html/fig-shtail-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Plot testing slow variation for <span class="math inline">\(\gamma \in (1,2)\)</span></figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="discussion-and-next-steps" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discussion and Next Steps</h1>
<p>The generative models considered so far are very simple, which is good since the goal is to find as simple a model as possible. However, it is clear now and perhaps unsurprising that the models shown here are not capable of modelling realistic network growth. This section is dedicated to discussing next steps for this project and address some questions left open. This is <strong>not</strong> a detailed plan for what is to come, for that see <a href="#sec-plan">Section&nbsp;6</a>.</p>
<p>The models from <a href="#sec-gen">Section&nbsp;3.2</a> are very limited when it comes to the actual growth of the network. Whenever a new vertex joins the network it brings a fixed number of edges with it that remain permanently, this is the only way that edges are added and thus the degrees changed. Below are some modifications that could be made to address this issue:</p>
<ul>
<li>Allow removal of edges throughout the networks growth.</li>
<li>Allow edges to be made between already existing vertices in the network.</li>
<li>Bring a random number of edges when a vertex is added.</li>
</ul>
<p>It is possible to include all of these into a model with the modification that at each time step you do one of three different steps (Growth, Connection, Removal) with certain probabilities where the number of edges added at each growth step is a discrete random variable. Something similar could be done for the connection and removal steps.</p>
<p>Additionally, all of the models assume a constant preferential attachment function both over time and across vertices. To address this the preferential attachment function could be allowed to change over time and perhaps differ between vertices. This would allow a vertex to ‘age’ in a sense, and could also allow for ‘categories’ of vertices that share the same preferential attachment function which differs from those in other ‘categories’.</p>
</section>


<section id="references" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section id="sec-plan" class="level1 appendix" data-number="6"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">6</span> Updated Project Plan</h2><div class="quarto-appendix-contents">

</div></section><section id="training" class="level1 appendix" data-number="7"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">7</span> Training</h2><div class="quarto-appendix-contents">


</div></section><section id="funding-and-stipend" class="level2 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">Funding and Stipend</h2><div class="quarto-appendix-contents">

<p>The funding for this project expires on <strong>17th March 2027</strong>.</p>
</div></section><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="list">
<div id="ref-fmh09" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Fraga Alves M, Haan L, Neves C (2009) A test procedure for detecting super-heavy tails. Journal of Statistical Planning and Inference 139. <a href="https://doi.org/10.1016/j.jspi.2008.04.026">https://doi.org/10.1016/j.jspi.2008.04.026</a></div>
</div>
<div id="ref-shimura12" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Shimura T (2012) Discretization of distributions in the maximum domain of attraction. Extremes 15:299–317. <a href="https://doi.org/10.1007/s10687-011-0137-7">https://doi.org/10.1007/s10687-011-0137-7</a></div>
</div>
<div id="ref-hds24" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Hitz AS, Davis RA, Samorodnitsky G (2024) Discrete extremes. Journal of Data Science 1–13. <a href="https://doi.org/10.6339/24-JDS1120">https://doi.org/10.6339/24-JDS1120</a></div>
</div>
<div id="ref-agn22" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Ahmad T, Gaetan C, Naveau P (2022) <a href="https://arxiv.org/abs/2210.15253">Modelling of discrete extremes through extended versions of discrete generalized pareto distribution</a>. ArXiv e-prints</div>
</div>
<div id="ref-Rohrbeck_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Rohrbeck C, Eastoe EF, Frigessi A, Tawn JA (2018) <span class="nocase">Extreme value modelling of water-related insurance claims</span>. The Annals of Applied Statistics 12(1):246–282. <a href="https://doi.org/10.1214/17-AOAS1081">https://doi.org/10.1214/17-AOAS1081</a></div>
</div>
<div id="ref-coles2001" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Coles S (2001) <a href="https://books.google.co.uk/books?id=2nugUEaKqFEC">An introduction to statistical modeling of extreme values</a>. Springer</div>
</div>
<div id="ref-mac2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Scarrott C, MacDonald A (2012) A review of extreme value threshold estimation and uncertainty quantification. Revstat Statistical Journal 10:33–60. <a href="https://doi.org/10.57805/revstat.v10i1.110">https://doi.org/10.57805/revstat.v10i1.110</a></div>
</div>
<div id="ref-rudas07" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Rudas A, Tóth B, Valkó B (2007) Random trees and general branching processes. Random Structures &amp; Algorithms 31(2):186–202. https://doi.org/<a href="https://doi.org/10.1002/rsa.20137">https://doi.org/10.1002/rsa.20137</a></div>
</div>
<div id="ref-Barabasi99" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Barabási A-L, Albert R (1999) Emergence of scaling in random networks. Science 286(5439):509–512. <a href="https://doi.org/10.1126/science.286.5439.509">https://doi.org/10.1126/science.286.5439.509</a></div>
</div>
<div id="ref-barabasibook" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Barabási AL, PÃ3sfai MÃ (2016) <a href="https://books.google.co.uk/books?id=iLtGDQAAQBAJ">Network science</a>. Cambridge University Press</div>
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>