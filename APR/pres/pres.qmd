---
title: "Annual Progress Review"
author: "Thomas Boughen"
date: 2024-06-17
format: 
  revealjs:
    footer: twboughen.github.io
    logo: imgs/University_of_Newcastle_Coat_of_Arms.png
    theme: default
    institute: Newcastle University
    output-file: 'index.html'
engine: knitr
bibliography: ../report/references.bib
---
## Motivation {.smaller}

- Want a simple generative model that can model many real networks adequately.

#### Example degree distributions of real networks
```{r,echo=FALSE, warning=FALSE, message=FALSE,cache=FALSE, dev = "png", dev.args=list(bg="transparent")}
#| fig-width: 10
#| fig-asp: 0.25
#| out-width: 100%
source('../scripts/plot_dir.R')
library(ggplot2)
dfs_full = konect_to_df_dir('../data/pres_data_1', return_names=T)
dfs = dfs_full$dat
nms = dfs_full$names
for(i in 1:length(nms)){
  nms[i] = strsplit(nms[i], 'out.')[[1]][2]
}
df = dfs[[1]]
df$from = nms[1]
df$surv = c(1, (1-cumsum(df$Freq)/sum(df$Freq))[-nrow(df)])

for(i in 2:length(nms)){
  temp = dfs[[i]]
  temp$surv = c(1, (1-cumsum(temp$Freq)/sum(temp$Freq))[-nrow(temp)])
  temp$from = nms[i]
  df = rbind(df, temp)
}

p = ggplot(df, aes(x=x, y = surv)) + geom_line() + scale_x_log10()+scale_y_log10()

p+facet_grid(cols=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0)) +
       theme(
         # panel.background = element_rect(fill='transparent'),
         plot.background = element_rect(fill='transparent', color=NA),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         legend.background = element_rect(fill='transparent'),
         legend.box.background = element_rect(fill='transparent')
       )
```
:::{.fragment}
- Power law like behaviour (for the bulk of the data)
:::
:::{.fragment}
- This behaviour tapers off in the extreme values
:::

::: {.notes}

- Want a network generative model that is fairly simple but flexible enough to model a wide range of real networks.
- Some examples of the degree distributions of real networks, shown as a log-log plot of the survival.
- Show some signs of power-law like behaviour for the bulk of the degrees
- This behaviour tapers off at the extremes of the distribution, more significantly at the right tail than the left


First step towards finding a model that generates realistic networks, is to find a suitable model for the degree distributions of real networks.

Should give some idea of what kinds of models to use.
:::

# Modelling degree distributions

::: {.notes}
Since the degree distributions seem to deviate from a power law at extreme values. 
Natural to look to extreme value theory.
:::

## Continuous Extremes Approach {.incremental}

Could use GP to model the peaks over threshold

. . . 

- Have to choose a threshold and split the data

. . . 

- Makes comparing likelihoods of models difficult

. . . 

- Would like a less empirical way of fitting model

. . . 

Could use a mixture that can model all of the data.

:::{.fragment style="color:red;"}
But degree of a vertex is not continuous.
:::
 
::: {.notes}

- Choosing threshold often done empirically, using threshold stability plot
- As threshold splits the data, cant compare likelihoods

- Since want to investigate degree distribution of many real networks, would like a less involved approach.

- Since, exhibits power-law behaviour up until a certain point. 

Could use a sliced mixture that can model all of the degrees, with a GP modelling the right tail

However, since degree of a vertex is not continuous it would be more appropriate to use a discrete model.


:::


## Discrete Extreme Value Theory

1. Discretisation of Generalised Pareto Distribution
2. Spliced Mixture Model
3. A useful quantity

## Integral Generalised Pareto Distribution {.smaller}

Similar to that defined by @Rohrbeck_2018

$$
\Pr(Y=y|Y>u) = \left(1+\displaystyle\frac{\xi(y+1-\lceil u\rceil)}{\sigma_0+\xi\lceil u\rceil}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-\lceil u\rceil)}{\sigma_0+\xi\lceil u\rceil}\right)_+^{-1/\xi}
$$

For $y=\lceil u\rceil,\lceil u\rceil+1, \ldots$ and $\xi \in \mathbb R$ and $u, \sigma_0 \in \mathbb R^+.$

Where $\xi$, $\sigma_0$,$u$ are the shape, scale, and threshold parameters respectively.

- $\xi<0 \rightarrow$ Negative Weibull $\qquad \mathcal D(\Psi_\alpha)$
- $\xi=0 \rightarrow$ Gumbel $\qquad\mathcal D(\Lambda)$
- $\xi>0 \rightarrow$ Fréchet $\qquad\mathcal D(\Phi_\alpha)$

## IGP Spliced Mixture {.smaller}

In general the IGP spliced mixture takes the form:

$$
f(y) = \begin{cases}
(1-\phi)g(x), & y=1,2,\ldots, v\\
\phi\left[\left(1+\displaystyle\frac{\xi(y+1-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}\right],&y=v+1, v+2,\ldots
\end{cases}
$$
where $g$ is some discrete distribution with support $\{1,2,\ldots,v\}$.

. . .

Want power law behaviour for bulk, so take:
$$
g(y) = \displaystyle\frac{y^{-(\alpha+1})}{\sum_{k=1}^v k^{\alpha+1}}, \quad y=1,2,\ldots,v
$$
for some $\alpha>0$.

## A Useful Quantity {.smaller}

For a distribution $F$ with survival function $\overline F$ and $n\in\mathbb Z^+$ let:

$$
\Omega(F,n) = \left(\log\displaystyle\frac{\overline F (n+1)}{\overline F (n+2)}\right)^{-1} - \left(\log\displaystyle\frac{\overline F (n)}{\overline F (n+1)}\right)^{-1}
$$
Useful for determining the domain of a attraction that a discrete distribution belongs to.

- $\lim_{n\rightarrow \infty} \Omega(F,n) = 0$, then is F recoverable to the Gumbel domain
- $\lim_{n\rightarrow \infty} \Omega(F,n) = \alpha^{-1}$, then is F is in the Fréchet domain, $\mathcal D(\Phi_\alpha)$

# Network Generative Models

## General Preferential Attachment {.smaller}

Starting with $G_0 = (V_0, E_0) = (\{1,\ldots,m_0\}, \emptyset)$. At each time $t\ge1$,  $G_t = (V_t, E_t)$ is generated by the following rules:

. . .

**Growth**: Add a new vertex to the vertex set i.e. 
$$
V_t = V_{t-1} \cup \{t+m_0\}
$$

. . .

**Preferential Attachment**: Add $m\le m_0$ edges connecting the new vertex to the existing vertices selected at random with weights proportional to a function of their degree i.e.:

$$
E_t  = E_{t-1} \cup \{\tilde e_1,\ldots,\tilde e_m\}
$$

where $\tilde e_j = \{t,\tilde v\}$ and $\tilde v = i$ with weights 

$$
\displaystyle\frac{g(d(i))}{\sum_{w\in V_{t-1}} g(d(i))}, \qquad i\in V_{t-1}
$$

#### Degree distribution

$$
f(k) = \displaystyle\frac{\lambda^*}{g(k) + \lambda^*}\prod_{i=0}^{k-1}\displaystyle\frac{g(i)}{g(i)+\lambda^*}\quad\text{ where} \quad \sum_{n=1}^\infty \prod_{i=1}^{n-1}\displaystyle\frac{g(i)}{g(i)+\lambda^*}=1

$$

## Special Cases {.smaller .center}
:::: {.columns}

::: {.column width="50%"}
### Barabási-Albert

$$
g(k) = k
$$


#### Degree Distribution

$$
f(k) = \frac{2m(m+1)}{k(k+1)(k+2)}
$$
If $m=1$:
$$
f(k) = \frac{4}{k(k+1)(k+2)}
$$
Belongs to Fréchet domain of attraction. 

$$
\mathcal D (\Phi_2)
$$ 

:::

::: {.column width="50%" .fragment}
### Uniform Attachment

$$
g(k) = c
$$

#### Degree Distribution

$$
f(k) \approx \displaystyle\frac{e}{m}\exp\left(-\displaystyle\frac{k}{m}\right)
$$
If $m=1$:

$$
f(k) = \left(1\over2\right)^k
$$

Recoverable to Gumbel domain of attraction.

$$
\mathcal D(\Lambda)
$$

:::

::::

# Analysis

## IGP model fit {.smaller}
:::: {.columns}

::: {.column width="50%"}

:::{.r-stack}

::: {.fragment .fade-out fragment-index=1}
```{r,echo=FALSE, warning=FALSE, message=FALSE, cache=FALSE}
#| fig-width: 6
#| fig-asp: 1
#| out-width: 100%
res=readRDS('../data/mcmc.outputs/dir_out.rds')
source('../scripts/igp_functions.R')
nms = konect_to_df_dir('../data/data_for_mcmc', return_names=T)$names
for(i in 1:length(nms)){
  nms[i] = strsplit(nms[i], 'out.')[[1]][2]
}
n = ncol(res)
auto.mfrow(n)
x = par()$mfrow[1]
y = par()$mfrow[2]
mx_dat=0
min_prob=1
for(i in 1:n){
  d = res[,i]$dat
  mx_dat = max(mx_dat, max(d[,1]))
  min_prob = min(min_prob, d[nrow(d),2]/sum(d[,2]))
}

for(i in 1:n){
    x_ax = 'n'
    y_ax='n'
    marge = c(0,0,0,0)
    if(i %% x ==1){
      marge[2] = 0
      y_ax = NULL
    }
    if(i>n-x){
      x_ax=NULL
    }
    if(i>(y-1)*x){
      marge[1] = 2
    }
  mcmc_plot(res[,i]$dat, as.data.frame(res[,i]$res_thinned),
            xlim=c(1,mx_dat),ylim=c(min_prob,1),mar=marge,xaxt=x_ax, yaxt=y_ax)
  legend('bottomleft', legend=nms[i], pch=20)
}
```
:::

:::{.fragment .fade-in fragment-index=1}
- Large variety in posterior variance due to sample sizes
- Clear that $\alpha$ and $\xi$ not the same as BA and UA models.


Perhaps GPA model can provide more flexibility.
:::
:::

:::

::: {.column width="50%"}


:::{layout="[[33,33],[33,33]]"}
```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%
dat_list_names = konect_to_df_dir('../data/data_for_mcmc', return_names=T)$names
nms = gsub('[[:digit:]]+', '', unlist(strsplit(dat_list_names,'out.')))
nms=nms[nms!='']
df = res[,1]$res_thinned
df$from = nms[1]
for(i in 2:ncol(res)){
  temp = res[,i]$res_thinned
  temp$from = nms[i]
  df = rbind(df, temp)
}

p = ggplot(df,aes(x=v)) +geom_histogram(binwidth = 1,aes(y = ..density..))+
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank()) 
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))

```
```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%



p = ggplot(df,aes(x=a)) +stat_density() +
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank())+xlim(0,5) 
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))+labs(x=expression(alpha))

```

```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%



library(latex2exp)
 
p = ggplot(df,aes(x=xi)) +stat_density()+
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank()) +labs(x=TeX('$\\xi'))
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))
```

```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%



p = ggplot(df,aes(x=1/a)) +stat_density() +
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank())+xlim(0,5)+labs(x=TeX('$1 / \\alpha$'))
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))

```

:::
:::
::::


## GPA analyses

Now consider GPA models with preferential attachment function of the form:

$$
g(k) = k^{\gamma},\qquad \gamma>0
$$

:::{.fragment}
$\gamma=1$ corresponds to the BA model.
:::

## GPA domain of attraction

```{r, echo=FALSE, message=FALSE,warning=FALSE,cache=FALSE}
source('../scripts/omega.R')
g = function(s,a=1){
  return((s+1)^a)
}

x=1:200
n=6
a.list = rev(c(seq(0.7,1,length.out=n),seq(1,1.3,length.out=n)))
a.list = unique(a.list)
pal = fish(2*n-1,option = "Thalassoma_hardwicke")
df = data.frame(k=x)
df = cbind(df,omega.vec(x, g, a.list[1]))
# plot(x,df[,2], type='l', ylim = c(5e-2,max(omega.vec(x, g, a.list[1]))),log='xy',
#      ylab = 'omega', xlab = 'k', col=pal[1])
i=3
for(a in a.list[-1]){
  df = cbind(df,omega.vec(x, g, a))
  # lines(x,df[,i],col=pal[which(a.list==a)])
  i=i+1
}
# lines(x,omega.vec(x,g, 1),col=1, lty=2)

names(df)[-1] = round(a.list,3)

require(ggplot2)
require(reshape2)
require(fishualize)
df = melt(df, id.vars = 'k', variable.name = 'a')



pal = fish(2*n-1,option = "Bodianus_rufus")
ggplot(df, aes(k,value))+geom_line(aes(colour = a),linewidth=1) + scale_x_log10() + scale_y_log10() + 
  scale_color_manual(TeX('$\\gamma$'),values=pal)+labs(x=TeX('$k$'),y=TeX('$\\Omega(F,k)$'))
```

## Super Heavy tails

Say a distribution $F$ has super heavy tails if its survival function is slowly varying i.e:

$$
\lim_{x\rightarrow\infty}\displaystyle\frac{\bar F(tx)}{\bar F (x)} = 1,\qquad \forall t>0
$$ 

:::{.fragment}
Could gain insight into if a distribution has super heavy tails by plotting:
$$
\displaystyle\frac{\bar F(tx)}{\bar F (x)}
$$
:::

## Testing for super heavy tails {.smaller}

This time restricting $\gamma$ to $(1,2)$:

```{r,echo=FALSE,message=FALSE,warning=FALSE,cache=FALSE}
source('../scripts/omega.R')
g = function(s,a=1){
  return((s+1)^a)
}
t=5
k = round(10^seq(1,3,length.out=20))
n=10
a.list = rev(seq(1,2,length.out=2*n-1))
a.list = unique(a.list)
pal = fish(2*n-1,option = "Thalassoma_hardwicke")
df = data.frame(k=k)
df = cbind(df,CCDF_rat.vec(k,t,2,g,a.list[1]))
# plot(df[,1],df[,2], type='l',log='xy',
     # ylab = 'omega', xlab = 'k', col=pal[1])
for(a in a.list[-1]){
  df = cbind(df,CCDF_rat.vec(k,t,2,g,a))
  # lines(x,df[,i],col=pal[which(a.list==a)])
}
# lines(x,CCDF_rat.vec(k,t,2,g,1),col=1, lty=2)

names(df)[-1] = round(a.list,3)


df = melt(df, id.vars = 'k', variable.name = 'a')



pal = fish(2*n-1,option = "Bodianus_rufus")
p=ggplot(df, aes(k,value))+geom_line(aes(colour = a),linewidth=1)+scale_x_log10()+scale_color_manual(values=pal)+theme(legend.position="none",axis.title.y = element_text(angle=0))
p + labs(x=TeX('$k$'),y=TeX('$\\frac{1-F(tk)}{1-F (k)}$') )
```


# Next Steps

##







## References









