---
title: "Annual Progress Review"
author: "Thomas Boughen"
date: 2024/06/17
date-format: "DD/MM/YYYY"
format: 
  revealjs:
    footer: twboughen.github.io
    logo: https://raw.githubusercontent.com/TWBoughen/phd/main/APR/pres/imgs/University_of_Newcastle_Coat_of_Arms.png
    theme: default
    institute: Newcastle University
    width: 1920
    height: 1080
    margin: 0.1
editor: visual
server: shiny
bibliography: ../report/references.bib
csl: ../report/diabetologia.csl
engine: knitr
nocite: |
  @reactome, @pajek,@jazz,@caida,@meta
---

## Barabási-Albert Model @Barabasi99 

```{css}
.cell.panel-sidebar{
  background-color:transparent;
  border-width:0px;
}
.cell.panel-input{
  background-color:transparent;
  border-width:0px;
  
}
.shiny-plot-output{
  overflow:hidden;
}

#go{
  border-width:0px;
  width:100%;
}

```

::::{.columns}

:::{.column width="25%"}
```{r}
library(igraph)
library(visNetwork)
# visNetworkOutput("netPlot")
actionButton('go','BA simulation with m=1')

plotOutput('netplot2', height = "900px")
```
:::

:::{.column width="50%"}
**Initial State**

Starting with graph of $m_0>m$ vertices.

**Steps (for** $t\ge 1$)

1.  Add a new vertex.
2.  Randomly add $m$ edges from the new vertex to those already in the network, with weights proportional to their degree, $d(i)$

**Properties**

-   Generates a power law degree distribution.
-   Implements a "rich get richer" scheme.
:::
::::

## In Reality 

-   Power law degree distributions are rare @Broido_2019
-   Despite its nice properties BA may not be best for real networks

```{r,echo=FALSE, warning=FALSE, message=FALSE,cache=FALSE, dev = "png", dev.args=list(bg="transparent")}
#| fig-width: 10
#| fig-asp: 0.25
#| out-width: 100%
source('../scripts/plot_dir.R')
library(ggplot2)
library(latex2exp)
dfs_full = konect_to_df_dir('../data/pres_data_1', return_names=T)
dfs = dfs_full$dat
nms = dfs_full$names
for(i in 1:length(nms)){
  nms[i] = strsplit(nms[i], 'out.')[[1]][2]
}
df = dfs[[1]]
df$from = nms[1]
df$surv = c(1, (1-cumsum(df$Freq)/sum(df$Freq))[-nrow(df)])

for(i in 2:length(nms)){
  temp = dfs[[i]]
  temp$surv = c(1, (1-cumsum(temp$Freq)/sum(temp$Freq))[-nrow(temp)])
  temp$from = nms[i]
  df = rbind(df, temp)
}

p = ggplot(df, aes(x=x, y = surv)) + geom_line() + scale_x_log10()+scale_y_log10()

p+facet_grid(cols=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0)) +
       theme(
         # panel.background = element_rect(fill='transparent'),
         plot.background = element_rect(fill='transparent', color=NA),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         legend.background = element_rect(fill='transparent'),
         legend.box.background = element_rect(fill='transparent')
       )+xlab(latex2exp('Degree, $k$'))+ylab(latex2exp('1-$F(k)$'))
```

::: fragment
-   Can see some power law behaviour
-   Main deviation in the right tail

Begin to investigate degree distribution of real networks using extreme value theory.
:::

## Extreme Value Theory 

Common way to model peaks over threshold, $Y$, is to use the generalised Pareto (**GP**) distribution:

$$
\Pr(Y\le y | Y>u)  = \begin{cases}
1-\left(1+\displaystyle\frac{\xi (y-u)}{\sigma_0+\xi u}\right)^{-1/\xi},&\xi\ne 0 \\
1-\exp\left(-\displaystyle\frac{y-u}{\sigma_0}\right),&\xi = 0
\end{cases}
$$ Network data is **discrete** so instead model $\lfloor Y\rfloor$ and use integral generalised Pareto (**IGP**) distribution:

$$
\Pr(Y=y|Y>u) = \begin{cases}
\left(1+\displaystyle\frac{\xi(y+1-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}&,\xi\ne 0\\
\exp\left(-\displaystyle\frac{y+1-v}{\sigma_0}\right)-\exp\left(-\displaystyle\frac{y-v}{\sigma_0}\right)&,\xi=0
\end{cases}
$$ where $v=\lceil u\rceil$, $\xi \in \mathbb R$ and $u,\sigma_0\in\mathbb R^+$.

## Mixture Model

To avoid issues of threshold selection use a mixture that can model all of the data:

$$
f(y) = \begin{cases}
(1-\phi)\displaystyle\frac{y^{-(\alpha+1)}}{\sum_{k=1}^v k^{\alpha+1}}, & y=1,2,\ldots, v\\
\phi\left[\left(1+\displaystyle\frac{\xi(y+1-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}-\left(1+\displaystyle\frac{\xi(y-v)}{\sigma_0+\xi v}\right)_+^{-1/\xi}\right],&y=v+1, v+2,\ldots
\end{cases}
$$ where $\phi \in (0,1)$ and $\alpha\in\mathbb R^+$ @Rohrbeck_2018.

Uses a truncated power law for bulk of the data and the IGP for the right tail above a threshold $v$.

::: columns
::: {.column width="25%"}
```{r}
sliderInput("xi", '\\( \\xi \\)', 
            min = -1, max = 2, value = 0.5, step=0.05, width="450px", ticks=FALSE)
sliderInput("a", '\\( \\alpha \\)', 
            min = 0, max = 10, value = 0.5, step=0.1, width="450px", ticks=FALSE)
sliderInput("sig", '\\( \\sigma_0 \\)', 
            min = 1, max = 100, value = 30, step=0.1, width="450px", ticks=FALSE)
sliderInput("v", '\\( v \\)', 
            min = 1, max = 100, value = 30, step=1, width="450px", ticks=FALSE)
sliderInput("phi", '\\( \\phi \\)', 
            min = 0, max = 0.5, value = 0.05, step=0.01, width="450px", ticks=FALSE)
```
:::

::: {.column width="75%"}
```{r}
plotOutput("mixplot", height = '500px', width='1200px')
```
:::
:::

## Model Fit

::: r-stack
::: {.columns .fragment .fade-left .fade-out fragment-index="1"}
::: {.column width="50%"}
-   Model fits well for real and simulated data.
-   Some evidence for a third component.
:::

::: {.column width="50%"}
```{r,echo=FALSE, warning=FALSE, message=FALSE, cache=FALSE}
#| fig-width: 6
#| fig-asp: 1
#| out-width: 100%
res=readRDS('../data/mcmc.outputs/dir_out.rds')
source('../scripts/igp_functions.R')
nms = konect_to_df_dir('../data/data_for_mcmc', return_names=T)$names

for(i in 1:length(nms)){
  nms[i] = strsplit(nms[i], 'out.')[[1]][2]
}
nms = c('jazz', 'meta', 'as-caida','BA simulated','pajek-erdos', 'reactome','UA simulated')
n = ncol(res)
auto.mfrow(n)
x = par()$mfrow[1]
y = par()$mfrow[2]
mx_dat=0
min_prob=1
for(i in 1:n){
  d = res[,i]$dat
  mx_dat = max(mx_dat, max(d[,1]))
  min_prob = min(min_prob, d[nrow(d),2]/sum(d[,2]))
}

for(i in 1:n){
    x_ax = 'n'
    y_ax='n'
    marge = c(0,0,0,0)
    if(i %% x ==1){
      marge[2] = 0
      y_ax = NULL
    }
    if(i>n-x){
      x_ax=NULL
    }
    if(i>(y-1)*x){
      marge[1] = 2
    }
    if(i %in% c(1,4,7)){
      marge[2] = 3
      y_ax=NULL
    }
    
  mcmc_plot(res[,i]$dat, as.data.frame(res[,i]$res_thinned),
            xlim=c(1,mx_dat),ylim=c(min_prob,1),mar=marge,xaxt=x_ax, yaxt=y_ax)
  legend('bottomleft', legend=nms[i], pch=20)
}
```
:::
:::

::: {.columns .fragment .fade-left fragment-index="1"}
::: {.column width="50%"}
-   Large range of values of $\xi$ and $\alpha$
-   Nothing really matches uniform attachment or BA
-   $1/\xi$ and $\alpha$ aren't close

Not enough flexibility from BA and UA models, so look to the more general case.
:::

::: {.column width="50%"}
::: {layout="[[33,33],[33,33]]"}
```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%
dat_list_names = konect_to_df_dir('../data/data_for_mcmc', return_names=T)$names
nms = gsub('[[:digit:]]+', '', unlist(strsplit(dat_list_names,'out.')))
nms=nms[nms!='']
nms = c('jazz', 'meta', 'as-caida','BA simulated','pajek-erdos', 'reactome','UA simulated')
df = res[,1]$res_thinned
df$from = nms[1]
for(i in 2:ncol(res)){
  temp = res[,i]$res_thinned
  temp$from = nms[i]
  df = rbind(df, temp)
}

p = ggplot(df,aes(x=v)) +geom_histogram(binwidth = 1,aes(y = ..density..))+
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank()) 
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))

```

```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%



p = ggplot(df,aes(x=a)) +stat_density(n=2^10) +
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank())+xlim(0,5) 
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))+labs(x=expression(alpha))

```

```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%



library(latex2exp)
 
p = ggplot(df,aes(x=xi)) +stat_density()+
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank()) +labs(x=TeX('$\\xi'))
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))
```

```{r, warning=FALSE, message=FALSE, echo=FALSE,cache=FALSE}
#| fig-width: 4
#| fig-asp: 1
#| out-width: 100%



p = ggplot(df,aes(x=1/a)) +stat_density(n=2^10) +
  theme( 
      axis.text.y=element_blank(), 
      axis.ticks.y=element_blank())+xlim(0,7)+labs(x=TeX('$1 / \\alpha$'))
p+facet_grid(rows=vars(from),scales="free", switch = 'y') + theme(strip.text.y.left = element_text(angle = 0))

```
:::
:::
:::
:::

## General Preferential Attachment 

**Initial State**

Starting with graph of $m_0>m$ vertices.

**Steps (for** $t\ge 1$)

1.  Add a new vertex.
2.  Randomly add $m$ edges from the new vertex to those already in the network, with weights proportional to a function of their degree, $g(d(i))$.

**Limiting Degree Distribution** @rudas07

If $m=1$

$$
f(k) = \displaystyle\frac{\lambda^*}{g(k) + \lambda^*}\prod_{i=0}^{k-1}\displaystyle\frac{g(i)}{g(i)+\lambda^*}\quad\text{ where} \quad \sum_{n=1}^\infty \prod_{i=1}^{n-1}\displaystyle\frac{g(i)}{g(i)+\lambda^*}=1
$$

## Special Cases

::: columns
::: {.column width="50%"}
### Barabási-Albert

$$
g(k) = k
$$

#### Degree Distribution @barabasibook 

$$
f(k) = \frac{2m(m+1)}{k(k+1)(k+2)}
$$ If $m=1$: $$
f(k) = \frac{4}{k(k+1)(k+2)}
$$

Heavy tailed
:::

::: {.column width="50%"}
### Uniform Attachment

$$
g(k) = c
$$

#### Degree Distribution @Barabasi99

$$
f(k) \approx \displaystyle\frac{e}{m}\exp\left(-\displaystyle\frac{k}{m}\right)
$$ If $m=1$:

$$
f(k) = \left(1\over2\right)^k
$$

Light tailed
:::

::: {.fragment color="red"}
What if $g(k)=k^\gamma$
:::
:::

## Studying the GPA model 

Need a way to study a discrete distribution at the right tail. @shimura12

$$
\Omega(F,k) = \left(\log\displaystyle\frac{\overline F (k+1)}{\overline F (k+2)}\right)^{-1} - \left(\log\displaystyle\frac{\overline F (k)}{\overline F (k+1)}\right)^{-1}
$$

-   $\lim_{n\rightarrow \infty} \Omega(F,n) = 0$, then F has light tails
-   $\lim_{n\rightarrow \infty} \Omega(F,n) = \alpha^{-1}$, then F has heavy tails

No result for $\Omega(F,k)$ diverging but taking $\alpha \downarrow 0$ gives: $$
\lim_{n\rightarrow \infty} \Omega(F,n) = \infty
$$ Taking $\alpha \downarrow 0$ corresponds to a definition of super heavy tails (slow variation of survival function).

## Numerical results for GPA ($\Omega(F,k)$)

```{r, echo=FALSE, message=FALSE,warning=FALSE,cache=FALSE}
source('../scripts/omega.R')
g = function(s,a=1){
  return((s+1)^a)
}

x=1:200
n=6
a.list = rev(c(seq(0.6,1,length.out=n),seq(1,2,length.out=n)))
a.list = unique(a.list)
pal = fish(2*n-1,option = "Thalassoma_hardwicke")
df = data.frame(k=x)
df = cbind(df,omega.vec(x, g, a.list[1]))
# plot(x,df[,2], type='l', ylim = c(5e-2,max(omega.vec(x, g, a.list[1]))),log='xy',
#      ylab = 'omega', xlab = 'k', col=pal[1])
i=3
for(a in a.list[-1]){
  df = cbind(df,omega.vec(x, g, a))
  # lines(x,df[,i],col=pal[which(a.list==a)])
  i=i+1
}
# lines(x,omega.vec(x,g, 1),col=1, lty=2)

names(df)[-1] = round(a.list,3)

require(ggplot2)
require(reshape2)
require(fishualize)
df = melt(df, id.vars = 'k', variable.name = 'a')



pal = fish(2*n-1,option = "Bodianus_rufus")
ggplot(df, aes(k,value))+geom_line(aes(colour = a),linewidth=1) + scale_x_log10() + scale_y_log10() + 
  scale_color_manual(TeX('$\\gamma$'),values=pal)+labs(x=TeX('$k$'),y=TeX('$\\Omega(F,k)$'))
```

## Numerical results for GPA (slow variation)

```{r,echo=FALSE,message=FALSE,warning=FALSE,cache=FALSE}
source('../scripts/omega.R')
g = function(s,a=1){
  return((s+1)^a)
}
t=5

k = round(10^seq(1,3,length.out=20))
# n=10
# a.list = rev(seq(1,2,length.out=2*n-1))
# a.list = unique(a.list)


pal = fish(2*n-1,option = "Thalassoma_hardwicke")
df = data.frame(k=k)
df = cbind(df,CCDF_rat.vec(k,t,2,g,a.list[1]))
# plot(df[,1],df[,2], type='l',log='xy',
     # ylab = 'omega', xlab = 'k', col=pal[1])
for(a in a.list[-1]){
  df = cbind(df,CCDF_rat.vec(k,t,2,g,a))
  # lines(x,df[,i],col=pal[which(a.list==a)])
}
# lines(x,CCDF_rat.vec(k,t,2,g,1),col=1, lty=2)

names(df)[-1] = round(a.list,3)


df = melt(df, id.vars = 'k', variable.name = 'a')



pal = fish(2*n-1,option = "Bodianus_rufus")
p=ggplot(df, aes(k,value))+geom_line(aes(colour = a),linewidth=1)+scale_x_log10()+scale_color_manual(TeX('$\\gamma$'),values=pal)
p + labs(x=TeX('$k$'),y=TeX('$\\frac{1-F(tk)}{1-F (k)}$') )
```

# Next Steps {.incremental}

-   Verify empirical results with theory
-   Consider adding a third component to the mixture
-   Modify GPA model to be more flexible
    -   Vertex and Edge deletion
    -   Random number of edges
    -   Changing attachment function $g$


# References

```{r}
#| context: server



library(visNetwork)
library(wdnet)
library(ggnetwork)
library(GGally)
library(network)
library(sna)
library(intergraph)
library(igraph)
library(gridExtra)
library(latex2exp)
start_time = isolate(Sys.time())

# df_raw = isolate(data.table::fread('../data/data_for_mcmc/out.jazz'))


max_rat=isolate(1.5e3)

autoInvalidate <- reactiveTimer(max_rat)

m=1

# g = isolate(sample_pa(1, power=1, m=m, directed = F, zero.appeal = 0.00000000001))


  ctrl_ba = rpa_control_preference(ftype='customized', pref = 's', spref='outs', tpref='ins')+ rpa_control_scenario(alpha=1, beta=0, gamma=0, xi=0, rho=0, beta.loop=TRUE,source.first = TRUE)
  init_net = list(
    edgelist = matrix(c(1, 2), nrow = 1),
    edgeweight = 1,
    directed =FALSE
  ) 


  vals = reactiveValues(i=m, degs=c(),g1 = rpanet(1, init_net, control=ctrl_ba), p=c(), q=c())
  


output$netPlot <- renderVisNetwork({
  data  = isolate(toVisNetworkData(g))
  visNetwork(nodes = data$nodes, edges = data$edges)
  # visIgraph(g)
})
  k = 1:200
  m=1
  pk_ba = 2*m*(m+1) / (k*(k+1)*(k+2))
  
 
  
  
output$netplot2 <- renderPlot({
  isolate(vals$i<-vals$i+1)

  
  
  
    # g = sample_pa(vals$i, 1, m=m, directed=F, start.graph = g, zero.appeal = 0.000000000001)
  
  
  if(vals$i<=97){
    isolate(vals$g1 <- rpanet(1, vals$g1, control=ctrl_ba))
  }else{
    isolate(vals$g1 <- rpanet(10, vals$g1, control=ctrl_ba))
  }
  
  message(class(wdnet_to_igraph(vals$g1)))
  
  isolate(vals$degs<-igraph::degree(wdnet_to_igraph(vals$g1)))
  
  
  
        g <- isolate(wdnet_to_igraph(vals$g1))
        
      # ws <- degree(g)/sum(degree(g))
      
      cols = c(rep('black', length(V(g))-1),'black')
      lys_e = c(rep(1, length(E(g))-m),rep(1,m))
      par(mar=c(0,0,0,0))
      
      # plot(g, vertex.label=NA, vertex.color=cols, edge.lty=lys_e,vertex.size=3 )
      message(class(g))
      netplot <- ggnet2(g, size='degree', legend.position = '')

      
       
      # print(sort(unique(x)))
      isolate(vals$p<- table(vals$degs)/length(vals$degs))
      # print(names(p))
      par(mar=c(2,2,0,0))
      # plot(sort(unique(x)),as.numeric(p), log='xy', xlab='', ylab='')
      isolate(vals$q <- c(1,(1-cumsum(as.numeric(vals$p)/sum(as.numeric(vals$p))))[-length(vals$p)]))
  
      # plot(names(vals$p),vals$q , log='xy',pch=20)
      # legend('topright', legend=paste0('n = ',length(vals$degs)))
      # lines(k, c(1,1-cumsum(pk_ba)[-length(pk_ba)]))
      
   df = data.frame(p=as.numeric(names(vals$p)) ,q=vals$q)
   df_ba = data.frame(k=k, pk_ba=c(1,1-cumsum(pk_ba)[-length(pk_ba)]))
  degp <- ggplot(data=df, aes(x=p,y=q)) + geom_point() + scale_x_log10() + scale_y_log10() + xlab(TeX('Degree ($k$)')) + ylab(TeX("$1-F(k)$"))+labs(subtitle = paste0('n = ',length(vals$degs))) + geom_line(data=df_ba, aes(x=k, y=pk_ba), color='red')
  print(grid.arrange(netplot, degp,nrow=2, heights =c(1,1)))
  
  
  
    
    if(length(vals$degs)>=15){
      autoInvalidate <- reactiveTimer(100)
    }
    if(length(vals$degs)>=800){
      autoInvalidate <- reactiveTimer(5*60*1e3)
    }
    autoInvalidate()
  
},bg="transparent")



reset_plot<- eventReactive(input$go,{
   ctrl_ba = rpa_control_preference(ftype='customized', pref = 's', spref='outs', tpref='ins')+ rpa_control_scenario(alpha=1, beta=0, gamma=0, xi=0, rho=0, beta.loop=TRUE,source.first = TRUE)
  init_net = list(
    edgelist = matrix(c(1, 2), nrow = 1),
    edgeweight = 1,
    directed =FALSE
  )
  isolate(vals$g1<- rpanet(1, init_net, control=ctrl_ba))
  autoInvalidate <- reactiveTimer(1.5e3)
  isolate(vals$i<-m)
  
})

  observe({
    reset_plot()
  })
  
  
output$mixplot<-renderPlot({
  source('../scripts/igp_functions.R')
  par(mar=c(2,2,2,0))
  k=1:200
  phi=1-p_mix(input$v,1e4,0,input$a,input$xi,input$sig)
  q = p_mix(k,input$v,input$phi,input$a,input$xi+0.01,input$sig)
  plot(k,c(1,1-q[-length(q)]),log='xy', type='l', subtitle='Survival function log-log plot', xlab='Degree', ylab='1-F(x)', ylim=c(1e-3, 1))
})
  
  




```
