---
title: Annual Progress Review
author: 
  - name:  Thomas William Boughen
    affiliations: 
      - name: Newcastle University
        department: School of Mathematics, Statistics and Physics
number-sections: true
number-depth: 1
format: 
  pdf:
    documentclass: scrreprt
    papersize: a4
    fontsize: 10pt
    include-in-header: include-in-header.tex
    template-partials:
      - before-body.tex
    indent: false
    geometry:
      - inner=2cm
      - outer=2cm
      - top=2cm
      - bottom=2cm
      - headsep=22pt
      - headheight=11pt
      - footskip=33pt
      - ignorehead
      - ignorefoot
      - heightrounded
    output-file: 'doc'
    output-ext: 'pdf'
  html: 
    output-file: 'index'
    page-layout: full
    toc: true
  odt:
    output-file: 'doc'
editor: visual
bibliography: references.bib
keep-tex: true
---

```{r, echo=F, warning=F, message=F}
#compile using this line of code in console in same folder as this file
#quarto::quarto_render("doc.qmd", output_format = "all")

#pdftotext APR/report/doc.pdf - | wc -w 
#for word count
library(networkdata)
library(igraph)
source('../scripts/functions.R')
source('../scripts/new_functions.R')
# library(mvtnorm)
#loading data############################

x=degree(atp[[1]],mode='in')
x=x[x>0]
tennis = as.data.frame(table(x))
tennis[,1] = as.numeric(as.character(tennis[,1]))

harvard = read.csv('../data/harvard.txt')
colnames(harvard) = c('x', 'Freq')

data("protein", package='networkdata')
x = degree(protein)
protein.dat = as.data.frame(table(x[x>0]))
protein.dat[,1] = as.numeric(as.character(protein.dat[,1]))/2
colnames(protein.dat) = c('x', 'Freq')


df = load_data('../data/rpkg_20190129.csv')
df0 = df-1
x = df0$depends[df0$depends>0]
depends = as.data.frame(table(x))
depends[,1] = as.numeric(as.character(depends[,1]))
set.seed(123)
G = barabasi.game(3e4)
x = degree(G, mode='in')
x=x[x>0]
sim = as.data.frame(table(x))
sim[,1] = as.numeric(as.character(sim[,1]))

```

```{r, echo=F, warning=F, message=F}
g = function(s,a=1){
  return((s+1)^0.1)
}
f = Vectorize(function(k,lambda,g,a=1){
  if(k==0){
    return(lambda/(lambda+g(k,a)))
  }
  ks = 0:(k-1)
  fracs = 1 - (lambda/(lambda+g(ks,a)))
  return(lambda/(lambda+g(k,a)) * prod(fracs))
}, vectorize.args = 'k')


f_rat = Vectorize(function(k,t,lambda,g,a=1){
  return(log(f(t*k, lambda, g,a))-log(f(k,lambda, g,a)))
}, vectorize.args = 'k')

CDF = Vectorize(function(k,lambda,g,a=1){
  return(sum(f(0:(k-1), lambda, g,a)))
}, vectorize.args='k')
CCDF_rat = Vectorize(function(k,t,lambda, g,a=1){
 return((1-CDF(t*k, lambda, g,a))/(1-CDF(k, lambda, g,a))) 
}, vectorize.args = 'k')


omega = Vectorize(function(k,lambda,g,a=1){
  p1 = log((1-CDF(k+1,lambda,g,a))/(1-CDF(k+2,lambda,g,a)))^-1
  p2 = log((1-CDF(k,lambda,g,a))/(1-CDF(k+1,lambda,g,a)))^-1
  return(p1-p2)
}, vectorize.args = c('k','a'))
omega.vec = function(k,g,a=1){
  lambda = uniroot(cond.b, interval=c(0,30), g=g)$root
  return(omega(k,lambda,g,a))
}


# omega.vec(1:100, g)

cond.b = Vectorize(function(lambda, g){
  vals = 0:1e4
  fracs = g(vals)/(lambda+g(vals))
  out = 0
  for(n in 1:length(vals)){
    eps = prod(fracs[1:n])
    # print(eps)
    out = out + eps
    if(eps<1e-4){
      return(out-1)
    }
  }
  return(out-1)
}, vectorize.args = 'lambda')



```


# Intuition {#sec-int}


# Extremes {#sec-ext}
Since the aim is to gain understanding about the behaviour of the degree distribution of networks at the right tail, it seems natural to look to using methods from extreme value theory. However, networks by their nature are discrete and so it may not be best to be using methods that are usually used in relation to continuous random variables. For this reason, this section starts with a review of what theory exists for modelling the extreme values of continuous random variables before moving to details what can be used when instead considering discrete random variables as is the case for the degree distributions of random networks.

## Continuous Extremes {#sec-ce}

Studying the properties of the right tail of the distribution of a continuous random variable, means that the focus is on the largest values that the random variable can take. So, a natural place to start is to consider the distribution of the block maxima of such a random variable. That is, for a set of iid random variables $\{X_1,\ldots,X_n\}$ with common cumulative density function (cdf) $F$ what is the distribution of $M_n = \max\{X_1,\ldots,X_n\}$? This question is answered by the Fisher–Tippett–Gnedenko theorem [REF](or more simply the extreme value theorem).

:::{#thm-evt}

## Extreme Value Theorem
Let $X_1,\ldots,X_n$ be a sample of iid random variables with common cdf $F$ with block maxima $M_n = \max\{X_1,\ldots,X_n\}$ and suppose that there exists $a_n>0, b_n\in\mathbb R$ such that $\lim_{n\rightarrow\infty}\Pr(\frac{1}{a_n}[M_n-b_n]) = G(x)$, then $F$ is said to be in the domain of attraction of $G$, denoted $F\in\mathcal D(G)$ ,and $G$ is of one of three types:

- Gumbel: $\Lambda(x) = \exp\{-\exp(-x)\},\quad x \in \mathbb R$
- Fréchet: $\Phi_\alpha(x) = \exp\{-x^{-\alpha}\},\quad x\ge 0,\alpha>0$
- Weibull: $\Psi_\alpha(x) = \exp\{-x^{-a}\},\quad x<0,\alpha>0$

:::

While this is a useful result, it may prove difficult to find the sequences $a_n,b_n$ in practice, so a simpler method to establish what domain of attraction a distribution belongs to would be nice. Luckily, this can be done through the concept of regular variation and is what will be used to define the domains of attraction and tail-heaviness through the rest of this report.

:::{#def-doa}

## Domains of Attraction
The distribution $F$ belongs to the Fréchet domain of attraction $\mathcal D(\Phi_\alpha)$ if and only if its complement (the survival function) $\bar F$ is regularly varying with index $-\alpha$ i.e.:
$$
\bar F(x) = x^{-\alpha}L(x),\qquad \text{for } L \text{ slowly varying}
$$
A similar condition applies to the Weibull domain of attraction $\mathcal D(\Psi_\alpha)$ in that a distribution $F$ belongs to the Weibull domain of attraction if and only if:
$$
\bar F(x_F-x^{-1}) = x^{-\alpha}L(x),\qquad \text{for } L \text{ slowly varying}
$$
where $x_F$ is the finite right endpoint of the support of $F$.

The condition for the Gumbel domain of attraction is not as simple, a distribution $F$ belongs to the Gumbel domain if and only if there exists a positive function $a: \mathbb R \rightarrow \mathbb R^+$ and a $t\in \mathbb R$ such that:
$$
\lim_{x\rightarrow x_F} \frac{\bar F(x+ta(x))}{\bar F(x)} = e^{-t}
$$
:::

Throughout this report the term "heavy tailed" distribution will be used to describe any distribution in the Fréchet domain of attraction, although some of the literature refers to "heavy tailed" distributions as being the distributions that decay slower than the exponential.

At this point it will also be useful to introduce the concept of distributions that have super-heavy tails.

:::{#def-sht}

## Super Heavy Tails

[FIND SUPER HEAVY TAILS DEFINITION]

Additionally, if the survival function $\bar F$ is slowly varying itself then $F$ has super heavy tails i.e.
$$
\lim_{x\rightarrow\infty}\frac{\bar F(tx)}{\bar{F}(x)} = 1, \forall t\in\mathbb R^+ \implies \text{super heavy tails} 
$$
:::
It is possible to gather the main three types of extremal distributions into what is called the Generalised Extreme Value (GEV) distribution [REF].

:::{#def-gev}

## Generalised Extreme Value Distribution

Denoted by $\GEV(\mu,\sigma,\xi)$ the distribution is characterised by three parameters $\mu \in \mathbb R$ the location, $\sigma\in \mathbb R^+$ the scale, and the shape $\xi\in \mathbb R$. It has support on $\{x\in \mathbb R:1+\xi(x-\mu)/\sigma > 0\}$ and has cdf given by:

$$
G(x) = \begin{cases}\exp\left\{-\left(1+\frac{\xi(x-\mu)}{\sigma}\right)^{-1/\xi}\right\},&\xi\ne0\\
\exp\{-\exp(-\frac{x-\mu}{\sigma})\},&\xi=0
\end{cases}
$$
:::
The three types of extremal distribution are obtained from changing the shape parameter $\xi$, which corresponds to $1/\alpha$ in the definition of the domains of attraction. This change is generally to made so that increasing $\xi$ corresponds to increasing how heavy the tails of the distribution are. So, $\xi<0$ corresponds to the Weibull, $\xi>0$ the Fréchet, and $\xi=0$ the Gumbel.


While this is useful for modelling the distribution of block maxima of iid random variables, as seen in @sec-int, the data in question appears to follow power law like behaviour for the bulk of the data and then changes to various different shapes above a certain threshold. For this reason, it is perhaps more appropriate to consider the distribution of threshold exceedances.



:::{#def-gp}

## Generalised Pareto Distribution

The Generalised Pareto (GP) distribution can be obtained by using the GEV distribution and conditional probability such that for large enough threshold the GP distribution approximately describes the conditional distribution of threshold exceedances. More precisely, for large enough threshold $u$ and the change of variable to $Y=X-u$:
$$
\Pr(Y\le y | Y>0) = H(y) = \begin{cases}
1-\left(1+\frac{\xi y}{\sigma}\right)^{-1/\xi},&y>0,\xi\ne 0 \\
1-\exp\left(-\frac{y}{\sigma}\right),&y>0,\xi = 0
\end{cases}
$$
:::
Since this distribution was obtained using a $\text{GEV}(\mu,\sigma^*,\xi)$ the shape parameter $\xi$ is identical in both distributions and the shape parameter $\sigma$ is defined such that $\sigma = \sigma^* + \xi(u-\mu)$.

The vast majority of this theory is appropriate only for continuous data, and since the data being focused on is discrete, some results for discrete extremes should be introduced.

## Discrete Extremes

Moving to modelling extremes in a discrete has the potential to cause some issues when describing how heavy the tails of a distribution are and what domain of attraction belongs to. For example, the exponential distribution belongs to the Gumbel domain $\mathcal D(\Lambda)$ but its discrete counterpart (the geometric distribution)  does not belong to the Gumbel domain. So, care needs to be taken when attempting to discretise the results from @sec-ce. 

@shimura12 provides conditions for a discrete distribution to belong to the domain of attraction. In particular the following theorem which corresponds to Theorem 1 in @shimura12.

:::{#thm-shimura1}

## Discrete Domains of Attraction
(a) Every discretisation of distribution in $\mathcal D(\Phi_\alpha)$ remains in $\mathcal D(\Phi_\alpha)$.
(b) The discretisation of a distribution remains in $\mathcal D(\Lambda)$ if and only if the original is in $\mathcal D(\Lambda)\cap \mathcal L$. 

Where $\mathcal L$ is the set of long-tailed distributions that have the property:
$$
\lim_{x\rightarrow \infty}\frac{\overline F(x+1)}{\overline F(x)} = 1   
$$
:::
In addition to this theorem, Shimura also introduces a quantity that will become useful when deciding what domain of attraction a discrete distribution belongs to. In this report we will simply refer to it as the Omega function and is defined below:

:::{#def-omega}

## Omega Function

For a distribution $F$ with survival function $\overline F$ and some $n\in\mathbb Z^+$ let:

$$
\Omega(F,n) = \left(\log\frac{\overline F (n+1)}{\overline F (n+2)}\right)^{-1} - \left(\log\frac{\overline F (n)}{\overline F (n+1)}\right)^{-1}
$$
:::
This quantity will play an important role in @sec-meth when determining what kinds of degree distributions different network generative models are expected to lead to.

[ADD COMMENTS HERE ABOUT WHAT EXISTS IN THE DISCRETE EXTREMES FIELD]

# Networks

Networks are the structures that will be the source of data that the results from @sec-ext will be used to analyse. Networks appear across a wide range of fields when attempting to represent complex systems and the relationships between the components within, showing up in anything from micro-biology (e.g. protein interactions in cells) to sociology (e.g. the social network of Harvard graduates). 

This makes networks a valuable source of data and understanding the mechanics of the network generation process can provide insights to the components themselves and into the networks future.

## Mathematical Definitions

Networks on the face of it are fairly simple objects, nothing more than a collection of objects with connections between each other. Here, graphs constructed from vertices and edges will be used as an analogue for these networks. 

:::{#def-net}

## Graph/Network

A graph $G = (V,E)$ is constructed from a vertex set $V\in\mathbb Z^+$ and an edge set $E$. The edge set can take on one of two forms depending on if the graph is directed or un-directed. If the graph is directed then $E\subseteq V^2$ i.e the edge set is contained within the set of ordered pairs of vertices, whereas if the graph is **un-directed** then $E\subseteq [V]^2$ i.e. the edge set is contained within the set of un-ordered pairs of vertices. The focus from now on will be on un-directed networks and graphs.
:::

Throughout this section and the next the concept of a vertices "degree" will come up, and in fact the main focus of @sec-meth is the degree distribution of networks.

:::{#def-deg}

## Degree

For an un-directed graph a vertex's degree denoted $d(v)$ or $k_v$ for $v\in V$ is the number of edges that are connected to vertex $v$:
$$
d(v) = |\{\{e_1, e_2\}\in E : e_1=v \cup e_2=v\}|
$$
Directed graphs have something analogous, called the in-degree $d_{in}$, out-degree $d_{out}$ and total degree $d_tot$
:::

## Network Generative Models

### Uniform Attachment (UA)

### Barabási-Albert (BA)

### General Preferential Attachment (GPA)


# Methods {#sec-meth}



# Next Steps



{{< pagebreak >}}
# References {.unnumbered}
