<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Thomas William Boughen">

<title>Annual Progress Review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="doc_files/libs/clipboard/clipboard.min.js"></script>
<script src="doc_files/libs/quarto-html/quarto.js"></script>
<script src="doc_files/libs/quarto-html/popper.min.js"></script>
<script src="doc_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="doc_files/libs/quarto-html/anchor.min.js"></script>
<link href="doc_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="doc_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="doc_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="doc_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="doc_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-int" id="toc-sec-int" class="nav-link active" data-scroll-target="#sec-int"><span class="header-section-number">1</span> Intuition</a></li>
  <li><a href="#sec-ext" id="toc-sec-ext" class="nav-link" data-scroll-target="#sec-ext"><span class="header-section-number">2</span> Extremes</a>
  <ul class="collapse">
  <li><a href="#sec-ce" id="toc-sec-ce" class="nav-link" data-scroll-target="#sec-ce"><span class="header-section-number">2.1</span> Continuous Extremes</a></li>
  <li><a href="#discrete-extremes" id="toc-discrete-extremes" class="nav-link" data-scroll-target="#discrete-extremes"><span class="header-section-number">2.2</span> Discrete Extremes</a></li>
  </ul></li>
  <li><a href="#networks" id="toc-networks" class="nav-link" data-scroll-target="#networks"><span class="header-section-number">3</span> Networks</a>
  <ul class="collapse">
  <li><a href="#mathematical-definitions" id="toc-mathematical-definitions" class="nav-link" data-scroll-target="#mathematical-definitions"><span class="header-section-number">3.1</span> Mathematical Definitions</a></li>
  <li><a href="#network-generative-models" id="toc-network-generative-models" class="nav-link" data-scroll-target="#network-generative-models"><span class="header-section-number">3.2</span> Network Generative Models</a>
  <ul class="collapse">
  <li><a href="#uniform-attachment-ua" id="toc-uniform-attachment-ua" class="nav-link" data-scroll-target="#uniform-attachment-ua">Uniform Attachment (UA)</a></li>
  <li><a href="#barabási-albert-ba" id="toc-barabási-albert-ba" class="nav-link" data-scroll-target="#barabási-albert-ba">Barabási-Albert (BA)</a></li>
  <li><a href="#general-preferential-attachment-gpa" id="toc-general-preferential-attachment-gpa" class="nav-link" data-scroll-target="#general-preferential-attachment-gpa">General Preferential Attachment (GPA)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-meth" id="toc-sec-meth" class="nav-link" data-scroll-target="#sec-meth"><span class="header-section-number">4</span> Methods</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps"><span class="header-section-number">5</span> Next Steps</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="doc.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="doc.odt"><i class="bi bi-file"></i>OpenOffice</a></li></ul></div></nav>
</div>
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Annual Progress Review</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Thomas William Boughen </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Newcastle University
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  

</header>

<section id="sec-int" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Intuition</h1>
</section>
<section id="sec-ext" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Extremes</h1>
<p>Since the aim is to gain understanding about the behaviour of the degree distribution of networks at the right tail, it seems natural to look to using methods from extreme value theory. However, networks by their nature are discrete and so it may not be best to be using methods that are usually used in relation to continuous random variables. For this reason, this section starts with a review of what theory exists for modelling the extreme values of continuous random variables before moving to details what can be used when instead considering discrete random variables as is the case for the degree distributions of random networks.</p>
<section id="sec-ce" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-ce"><span class="header-section-number">2.1</span> Continuous Extremes</h2>
<p>Studying the properties of the right tail of the distribution of a continuous random variable, means that the focus is on the largest values that the random variable can take. So, a natural place to start is to consider the distribution of the block maxima of such a random variable. That is, for a set of iid random variables <span class="math inline">\(\{X_1,\ldots,X_n\}\)</span> with common cumulative density function (cdf) <span class="math inline">\(F\)</span> what is the distribution of <span class="math inline">\(M_n = \max\{X_1,\ldots,X_n\}\)</span>? This question is answered by the Fisher–Tippett–Gnedenko theorem <a href="or%20more%20simply%20the%20extreme%20value%20theorem">REF</a>.</p>
<div id="thm-evt" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Extreme Value Theorem) </strong></span>Let <span class="math inline">\(X_1,\ldots,X_n\)</span> be a sample of iid random variables with common cdf <span class="math inline">\(F\)</span> with block maxima <span class="math inline">\(M_n = \max\{X_1,\ldots,X_n\}\)</span> and suppose that there exists <span class="math inline">\(a_n&gt;0, b_n\in\mathbb R\)</span> such that <span class="math inline">\(\lim_{n\rightarrow\infty}\Pr(\frac{1}{a_n}[M_n-b_n]) = G(x)\)</span>, then <span class="math inline">\(F\)</span> is said to be in the domain of attraction of <span class="math inline">\(G\)</span>, denoted <span class="math inline">\(F\in\mathcal D(G)\)</span> ,and <span class="math inline">\(G\)</span> is of one of three types:</p>
<ul>
<li>Gumbel: <span class="math inline">\(\Lambda(x) = \exp\{-\exp(-x)\},\quad x \in \mathbb R\)</span></li>
<li>Fréchet: <span class="math inline">\(\Phi_\alpha(x) = \exp\{-x^{-\alpha}\},\quad x\ge 0,\alpha&gt;0\)</span></li>
<li>Weibull: <span class="math inline">\(\Psi_\alpha(x) = \exp\{-x^{-a}\},\quad x&lt;0,\alpha&gt;0\)</span></li>
</ul>
</div>
<p>While this is a useful result, it may prove difficult to find the sequences <span class="math inline">\(a_n,b_n\)</span> in practice, so a simpler method to establish what domain of attraction a distribution belongs to would be nice. Luckily, this can be done through the concept of regular variation and is what will be used to define the domains of attraction and tail-heaviness through the rest of this report.</p>
<div id="def-doa" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Domains of Attraction) </strong></span>The distribution <span class="math inline">\(F\)</span> belongs to the Fréchet domain of attraction <span class="math inline">\(\mathcal D(\Phi_\alpha)\)</span> if and only if its complement (the survival function) <span class="math inline">\(\bar F\)</span> is regularly varying with index <span class="math inline">\(-\alpha\)</span> i.e.: <span class="math display">\[
\bar F(x) = x^{-\alpha}L(x),\qquad \text{for } L \text{ slowly varying}
\]</span> A similar condition applies to the Weibull domain of attraction <span class="math inline">\(\mathcal D(\Psi_\alpha)\)</span> in that a distribution <span class="math inline">\(F\)</span> belongs to the Weibull domain of attraction if and only if: <span class="math display">\[
\bar F(x_F-x^{-1}) = x^{-\alpha}L(x),\qquad \text{for } L \text{ slowly varying}
\]</span> where <span class="math inline">\(x_F\)</span> is the finite right endpoint of the support of <span class="math inline">\(F\)</span>.</p>
<p>The condition for the Gumbel domain of attraction is not as simple, a distribution <span class="math inline">\(F\)</span> belongs to the Gumbel domain if and only if there exists a positive function <span class="math inline">\(a: \mathbb R \rightarrow \mathbb R^+\)</span> and a <span class="math inline">\(t\in \mathbb R\)</span> such that: <span class="math display">\[
\lim_{x\rightarrow x_F} \frac{\bar F(x+ta(x))}{\bar F(x)} = e^{-t}
\]</span></p>
</div>
<p>Throughout this report the term “heavy tailed” distribution will be used to describe any distribution in the Fréchet domain of attraction, although some of the literature refers to “heavy tailed” distributions as being the distributions that decay slower than the exponential.</p>
<p>At this point it will also be useful to introduce the concept of distributions that have super-heavy tails.</p>
<div id="def-sht" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 (Super Heavy Tails) </strong></span>[FIND SUPER HEAVY TAILS DEFINITION]</p>
<p>Additionally, if the survival function <span class="math inline">\(\bar F\)</span> is slowly varying itself then <span class="math inline">\(F\)</span> has super heavy tails i.e. <span class="math display">\[
\lim_{x\rightarrow\infty}\frac{\bar F(tx)}{\bar{F}(x)} = 1, \forall t\in\mathbb R^+ \implies \text{super heavy tails}
\]</span></p>
</div>
<p>It is possible to gather the main three types of extremal distributions into what is called the Generalised Extreme Value (GEV) distribution [REF].</p>
<div id="def-gev" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 (Generalised Extreme Value Distribution) </strong></span>Denoted by <span class="math inline">\(\text{GEV}(\mu,\sigma,\xi)\)</span> the distribution is characterised by three parameters <span class="math inline">\(\mu \in \mathbb R\)</span> the location, <span class="math inline">\(\sigma\in \mathbb R^+\)</span> the scale, and the shape <span class="math inline">\(\xi\in \mathbb R\)</span>. It has support on <span class="math inline">\(\{x\in \mathbb R:1+\xi(x-\mu)/\sigma &gt; 0\}\)</span> and has cdf given by:</p>
<p><span class="math display">\[
G(x) = \begin{cases}\exp\left\{-\left(1+\frac{\xi(x-\mu)}{\sigma}\right)^{-1/\xi}\right\},&amp;\xi\ne0\\
\exp\{-\exp(-\frac{x-\mu}{\sigma})\},&amp;\xi=0
\end{cases}
\]</span></p>
</div>
<p>The three types of extremal distribution are obtained from changing the shape parameter <span class="math inline">\(\xi\)</span>, which corresponds to <span class="math inline">\(1/\alpha\)</span> in the definition of the domains of attraction. This change is generally to made so that increasing <span class="math inline">\(\xi\)</span> corresponds to increasing how heavy the tails of the distribution are. So, <span class="math inline">\(\xi&lt;0\)</span> corresponds to the Weibull, <span class="math inline">\(\xi&gt;0\)</span> the Fréchet, and <span class="math inline">\(\xi=0\)</span> the Gumbel.</p>
<p>While this is useful for modelling the distribution of block maxima of iid random variables, as seen in <a href="#sec-int">Section&nbsp;1</a>, the data in question appears to follow power law like behaviour for the bulk of the data and then changes to various different shapes above a certain threshold. For this reason, it is perhaps more appropriate to consider the distribution of threshold exceedances.</p>
<div id="def-gp" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4 (Generalised Pareto Distribution) </strong></span>The Generalised Pareto (GP) distribution can be obtained by using the GEV distribution and conditional probability such that for large enough threshold the GP distribution approximately describes the conditional distribution of threshold exceedances. More precisely, for large enough threshold <span class="math inline">\(u\)</span> and the change of variable to <span class="math inline">\(Y=X-u\)</span>: <span class="math display">\[
\Pr(Y\le y | Y&gt;0) = H(y) = \begin{cases}
1-\left(1+\frac{\xi y}{\sigma}\right)^{-1/\xi},&amp;y&gt;0,\xi\ne 0 \\
1-\exp\left(-\frac{y}{\sigma}\right),&amp;y&gt;0,\xi = 0
\end{cases}
\]</span></p>
</div>
<p>Since this distribution was obtained using a <span class="math inline">\(\text{GEV}(\mu,\sigma^*,\xi)\)</span> the shape parameter <span class="math inline">\(\xi\)</span> is identical in both distributions and the shape parameter <span class="math inline">\(\sigma\)</span> is defined such that <span class="math inline">\(\sigma = \sigma^* + \xi(u-\mu)\)</span>.</p>
<p>The vast majority of this theory is appropriate only for continuous data, and since the data being focused on is discrete, some results for discrete extremes should be introduced.</p>
</section>
<section id="discrete-extremes" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="discrete-extremes"><span class="header-section-number">2.2</span> Discrete Extremes</h2>
<p>Moving to modelling extremes in a discrete has the potential to cause some issues when describing how heavy the tails of a distribution are and what domain of attraction belongs to. For example, the exponential distribution belongs to the Gumbel domain <span class="math inline">\(\mathcal D(\Lambda)\)</span> but its discrete counterpart (the geometric distribution) does not belong to the Gumbel domain. So, care needs to be taken when attempting to discretise the results from <a href="#sec-ce">Section&nbsp;2.1</a>.</p>
<p><span class="citation" data-cites="shimura12">Shimura (<a href="#ref-shimura12" role="doc-biblioref">2012</a>)</span> provides conditions for a discrete distribution to belong to the domain of attraction. In particular the following theorem which corresponds to Theorem 1 in <span class="citation" data-cites="shimura12">Shimura (<a href="#ref-shimura12" role="doc-biblioref">2012</a>)</span>.</p>
<div id="thm-shimura1" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Discrete Domains of Attraction) </strong></span>&nbsp;</p>
<ol type="a">
<li>Every discretisation of distribution in <span class="math inline">\(\mathcal D(\Phi_\alpha)\)</span> remains in <span class="math inline">\(\mathcal D(\Phi_\alpha)\)</span>.</li>
<li>The discretisation of a distribution remains in <span class="math inline">\(\mathcal D(\Lambda)\)</span> if and only if the original is in <span class="math inline">\(\mathcal D(\Lambda)\cap \mathcal L\)</span>.</li>
</ol>
<p>Where <span class="math inline">\(\mathcal L\)</span> is the set of long-tailed distributions that have the property: <span class="math display">\[
\lim_{x\rightarrow \infty}\frac{\overline F(x+1)}{\overline F(x)} = 1   
\]</span></p>
</div>
<p>In addition to this theorem, Shimura also introduces a quantity that will become useful when deciding what domain of attraction a discrete distribution belongs to. In this report we will simply refer to it as the Omega function and is defined below:</p>
<div id="def-omega" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5 (Omega Function) </strong></span>For a distribution <span class="math inline">\(F\)</span> with survival function <span class="math inline">\(\overline F\)</span> and some <span class="math inline">\(n\in\mathbb Z^+\)</span> let:</p>
<p><span class="math display">\[
\Omega(F,n) = \left(\log\frac{\overline F (n+1)}{\overline F (n+2)}\right)^{-1} - \left(\log\frac{\overline F (n)}{\overline F (n+1)}\right)^{-1}
\]</span></p>
</div>
<p>This quantity will play an important role in <a href="#sec-meth">Section&nbsp;4</a> when determining what kinds of degree distributions different network generative models are expected to lead to.</p>
<p>Applying ideas from <a href="#sec-ce">Section&nbsp;2.1</a> to modelling discrete random variables has been approached from many different directions. What follows is a overview of some of the approaches that have been taken but will see use in this report.</p>
<p>One of the main issues when it comes to applying results from <a href="#sec-ce">Section&nbsp;2.1</a> to discrete data, is the discretisation of the GP distribution and making sure that it still maintains most of the same properties.</p>
<p>[AHMAD] introduces several ways to discretise the GP distribution including mixing the geometric distribution with a Gamma distribution, they also introduce an extended GP distribution (and its discretisation) which is obtained from a probability integral transform (PIT) of a distribution with support on <span class="math inline">\((0,1)\)</span>. This is a modification of how the regular GP is obtained, which is from a PIT uniform distribution on (0,1).</p>
<p>Also considering mixtures, [VALIQUETTE] investigated the tail properties of Poisson mixtures and found that changing the mixing distribution changes the tail heaviness of the mixed distribution. They divided the domain of attraction of the mixing distribution into various subsets that lead to different tail behaviours, through the limit of the ratio of consecutive values of the survival function. These limits do help describe the tail behaviour of the resulting mixture but do not quite correspond to different domains of attraction.</p>
<p>The approach used in <a href="#sec-meth">Section&nbsp;4</a> will be very similar to the one taken in [ROHRBECK] with a minor change to the derivation, this will be explained in detail in <a href="#sec-meth">Section&nbsp;4</a>.</p>
</section>
</section>
<section id="networks" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Networks</h1>
<p>Networks are the structures that will be the source of data that the results from <a href="#sec-ext">Section&nbsp;2</a> will be used to analyse. Networks appear across a wide range of fields when attempting to represent complex systems and the relationships between the components within, showing up in anything from micro-biology (e.g.&nbsp;protein interactions in cells) to sociology (e.g.&nbsp;the social network of Harvard graduates).</p>
<p>This makes networks a valuable source of data and understanding the mechanics of the network generation process can provide insights to the components themselves and into the networks future.</p>
<section id="mathematical-definitions" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="mathematical-definitions"><span class="header-section-number">3.1</span> Mathematical Definitions</h2>
<p>Networks on the face of it are fairly simple objects, nothing more than a collection of objects with connections between each other. Here, graphs constructed from vertices and edges will be used as an analogue for these networks.</p>
<div id="def-net" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6 (Graph/Network) </strong></span>A graph <span class="math inline">\(G = (V,E)\)</span> is constructed from a vertex set <span class="math inline">\(V\in\mathbb Z^+\)</span> and an edge set <span class="math inline">\(E\)</span>. The edge set can take on one of two forms depending on if the graph is directed or un-directed. If the graph is directed then <span class="math inline">\(E\subseteq V^2\)</span> i.e the edge set is contained within the set of ordered pairs of vertices, whereas if the graph is <strong>un-directed</strong> then <span class="math inline">\(E\subseteq [V]^2\)</span> i.e.&nbsp;the edge set is contained within the set of un-ordered pairs of vertices. The focus from now on will be on un-directed networks and graphs.</p>
</div>
<p>Throughout this section and the next the concept of a vertices “degree” will come up, and in fact the main focus of <a href="#sec-meth">Section&nbsp;4</a> is the degree distribution of networks.</p>
<div id="def-deg" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7 (Degree) </strong></span>For an un-directed graph a vertex’s degree denoted <span class="math inline">\(d(v)\)</span> or <span class="math inline">\(k_v\)</span> for <span class="math inline">\(v\in V\)</span> is the number of edges that are connected to vertex <span class="math inline">\(v\)</span>: <span class="math display">\[
d(v) = |\{e\in E : v \in e\}|
\]</span> Directed graphs have something analogous, called the in-degree <span class="math inline">\(d_{in}\)</span>, out-degree <span class="math inline">\(d_{out}\)</span> and total degree <span class="math inline">\(d_{tot}\)</span>. The in-degree of a vertex <span class="math inline">\(v\)</span> is the number edges with endpoint at <span class="math inline">\(v\)</span>, whereas the out-degree is the number of edges with start point at <span class="math inline">\(v\)</span> and the total degree is the sum of these i.e.:</p>
<span class="math display">\[\begin{align*}
d_{in}(v)&amp;= |\{(w_1,w_2)\in E: w_2=v \}|\\
d_{out}(v) &amp;= |\{(w_1,w_2)\in E: w_1=v \}|\\
d_{tot}(v) &amp;= d_{in}(v) + d_{out}(v)
\end{align*}\]</span>
</div>
<p>There are many reasons to analyse network like data, one of which is to gain an insight into the mechanics that governed the growth of the network. The next sub-section is focused on presenting several network generative models increasing in generality.</p>
</section>
<section id="network-generative-models" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="network-generative-models"><span class="header-section-number">3.2</span> Network Generative Models</h2>
<p>The models in this section are nested within one another, they all follow the same regiment that at each time-step a vertex is added to the network along with one or more edges that connect the new vertex to those already in the network.</p>
<section id="uniform-attachment-ua" class="level3">
<h3 class="anchored" data-anchor-id="uniform-attachment-ua">Uniform Attachment (UA)</h3>
<p>The first model dubbed the “uniform attachment model” is a simple model first presented in [UA REF] and is defined as follows:</p>
<div id="def-ua" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8 (Uniform Attachment Model) </strong></span>Start with a graph <span class="math inline">\(G_1 = (V_1, E_1) = (\{1,\ldots,m_0\}, \emptyset)\)</span>, at each time step <span class="math inline">\(t&gt;1\)</span> the graph is denoted by <span class="math inline">\(G_t=(V_t, E_t)\)</span> and generated by repeating the following two steps:</p>
<ol type="1">
<li><strong>Growth:</strong> Add a new vertex to the vertex set i.e.&nbsp; <span class="math display">\[
V_t=V_{t-1}\cup\{t\}
\]</span></li>
<li><strong>Attachment:</strong> Add <span class="math inline">\(m\le m_0\)</span> random edges between the new vertex and those already in the graph i.e.&nbsp; <span class="math display">\[
E_t = E_{t-1} \cup \tilde E
\]</span> where <span class="math inline">\(\tilde E = \{\tilde e_1,\ldots, \tilde e_m\}\)</span> and <span class="math inline">\(\tilde e_i = \{t,\tilde v_i\}\)</span> and <span class="math inline">\(\tilde v_i \sim U(V_{t-1})\)</span>.</li>
</ol>
</div>
<section id="expected-degree-distribution" class="level4">
<h4 class="anchored" data-anchor-id="expected-degree-distribution">Expected Degree Distribution</h4>
<p>As showing in [REF] the expected degree distribution of this model for large values of <span class="math inline">\(t\)</span> is: <span class="math display">\[
f(k) = \frac{e}{m}\exp\left(-\frac{k}{m}\right),\qquad k \ge m
\]</span> Since this distribution has exponential form, it is in the Gumbel domain of attraction.</p>
</section>
</section>
<section id="barabási-albert-ba" class="level3">
<h3 class="anchored" data-anchor-id="barabási-albert-ba">Barabási-Albert (BA)</h3>
<p>This model defined in <span class="citation" data-cites="Barabasi99">Barabási and Albert (<a href="#ref-Barabasi99" role="doc-biblioref">1999</a>)</span> and also very closely related to the Yule-Simon process from [YS REF] changes the attachment mechanism from being purely uniform on the vertices already in the network to being random with a probability proportional to the degrees of the vertices in the network.</p>
<div id="def-ba" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9 (Barabási-Albert Model) </strong></span>Starting with a graph <span class="math inline">\(G_1 = (V_1, E_1)\)</span> where <span class="math inline">\(V_1 = \{1,\ldots,m_0\}\)</span> and <span class="math inline">\(E_1 = \{\{v\}:v\in V_1\}\)</span> i.e a graph with <span class="math inline">\(m_0\)</span> vertices with one self-loop each. At each time step <span class="math inline">\(t&gt;1\)</span> the graph denoted by <span class="math inline">\(G_t = (V_1, E_1)\)</span> is generated by repeating the following:</p>
<ol type="1">
<li><strong>Growth:</strong> Add a new vertex to the vertex set i.e. <span class="math display">\[
V_t = V_{t-1} \cup \{t\}
\]</span></li>
<li><strong>Preferential Attachment:</strong> Add <span class="math inline">\(m\le m_0\)</span> edges between the new vertex and those already in the graph with probability proportional to each vertices degree i.e:</li>
</ol>
<p><span class="math display">\[
E_t= E_{t-1} \cup \tilde E
\]</span> where <span class="math inline">\(\tilde E = \{\tilde e_1,\ldots, \tilde e_m\}\)</span> and</p>
<span class="math display">\[\begin{align*}
\tilde e_i &amp;\sim \text{Cat}\left(V_{t-1},P \right)\\
P &amp;= \left\{\frac{d(v)}{\sum_{w\in V_{t-1}} d(w)} : v \in V_{t-1}\right\}
\end{align*}\]</span>
</div>
<section id="expected-degree-distriubtion" class="level4">
<h4 class="anchored" data-anchor-id="expected-degree-distriubtion">Expected Degree Distriubtion</h4>
<p>In the same paper (<span class="citation" data-cites="Barabasi99">Barabási and Albert (<a href="#ref-Barabasi99" role="doc-biblioref">1999</a>)</span>) it was shown that for large values of <span class="math inline">\(t\)</span> the expected degree distribution for this model is approximately: <span class="math display">\[
f(k) = \frac{2m^2t}{m_0+t}k^{-3} \approx 2m^2k^{-3},\qquad k\ge m
\]</span></p>
<p>This is clearly a regularly varying function and therefore in in the Fréchet domain of attraction <span class="math inline">\(\mathcal D(\Phi_2)\)</span>.</p>
</section>
</section>
<section id="general-preferential-attachment-gpa" class="level3">
<h3 class="anchored" data-anchor-id="general-preferential-attachment-gpa">General Preferential Attachment (GPA)</h3>
<p>This model generalises the BA model by instead of attaching the new edges with a probability proportional to vertices’ degrees, the new edges are attached with probability proportional to some function of the vertices’ degrees.</p>
<div id="def-gpa" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 10 (General Preferential Attachment Model) </strong></span>Starting with a graph <span class="math inline">\(G_1 = (V_1, E_1) = (\{1,\ldots,m_0\}, \emptyset)\)</span>, at each following time step <span class="math inline">\(t&gt;1\)</span> the graph is denoted by <span class="math inline">\(G_t = (V_t, E_t)\)</span> and is generated by repeating:</p>
<ol type="1">
<li><strong>Growth:</strong> Add a new vertex to the vertex set i.e. <span class="math display">\[
V_t = V_{t-1} \cup \{t\}
\]</span></li>
<li><strong>Preferential Attachment:</strong> Add <span class="math inline">\(m\le m_0\)</span> edges connecting the new vertex to those already in the graph selected at random proportional to a function of their degree(minus one)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> i.e.: <span class="math display">\[
E_t  = E_{t-1} \cup \tilde E
\]</span> where <span class="math inline">\(\tilde E = \{\tilde e_1,\ldots, \tilde e_m\}\)</span> and</li>
</ol>
<span class="math display">\[\begin{align*}
\tilde e_i &amp;\sim \text{Cat}\left([V_{t-1}]^2 \cap \{t\},P \right)\\
P &amp;= \left\{\frac{g(k_v-1)}{\sum_{w\in V_{t-1}} g(k_w-1)} : v \in V_{t-1}\right\}
\end{align*}\]</span>
<p>for some function <span class="math inline">\(g: \mathbb Z \mapsto \mathbb R^+\setminus\{0\}\)</span>, which will be referred to as the preferential attachment function</p>
</div>
<section id="expected-degree-dristribution" class="level4">
<h4 class="anchored" data-anchor-id="expected-degree-dristribution">Expected Degree Dristribution</h4>
<p>In [GPA REF] the expected degree distribution for <span class="math inline">\(m=1\)</span> was calculated in terms of the preferential attachment function does not have a general explicit form. It is defined as follows, let <span class="math inline">\(\lambda^*\)</span> be the solution, if it exists, to:</p>
<p><span class="math display">\[
1=\sum_{n=1}^\infty \prod_{i=1}^{n-1}\frac{g(i)}{g(i)+\lambda}
\]</span> then the expected degree distribution resulting from the GPA model has pmf:</p>
<p><span class="math display">\[
f(k) = \frac{\lambda^*}{g(k) + \lambda^*}\prod_{i=0}^{k-1}\frac{g(i)}{g(i)+\lambda^*}
\]</span> It is hard to see how this may behave in the tails for different preferential attachment functions, this will one the main foucses of the next section.</p>
</section>
</section>
</section>
</section>
<section id="sec-meth" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Methods</h1>
</section>
<section id="next-steps" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Next Steps</h1>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Barabasi99" class="csl-entry" role="listitem">
Barabási, Albert-László, and Réka Albert. 1999. <span>“Emergence of Scaling in Random Networks.”</span> <em>Science</em> 286 (5439): 509–12. <a href="https://doi.org/10.1126/science.286.5439.509">https://doi.org/10.1126/science.286.5439.509</a>.
</div>
<div id="ref-shimura12" class="csl-entry" role="listitem">
Shimura, Takaaki. 2012. <span>“Discretization of Distributions in the Maximum Domain of Attraction.”</span> <em>Extremes</em> 15 (September): 1–19. <a href="https://doi.org/10.1007/s10687-011-0137-7">https://doi.org/10.1007/s10687-011-0137-7</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The probabilities are proportional to the degree minus one to align with the results from [GPA REF]<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>